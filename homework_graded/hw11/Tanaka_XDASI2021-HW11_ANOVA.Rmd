---
title: "Homework 11: ANOVA"
subtitle: "XDASI Fall 2021"
author: "Ken Tanaka"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
```


# Q0: Load the data set and examine it

For this exercise, we will be looking at brood size and fertilization defects in a *C. elegans* gene called *mel-28*, alone and in combination with a mutation in a second gene that suppresses these phenotypes. There are 30 biological replicates for each condition. The measurements taken were:  

+ **Brood size** - number of eggs laid by one worm in one day  
+ **Fertilized** - number of eggs laid that were fertilized embryos

First, load the data and take a look at it. Make sure that the `genotype` column is a factor and that you set "WT" as the reference level.

*Hint: you can use either the `factor()` or `relevel()` commands to set/reorder the levels; what weird thing happens if you use `level()` instead?*

```{r}
# load the data
mel28tmp.df <- read.table("Ce_mel28_Emb_Ste.csv", sep=",", header = T, stringsAsFactors = T)

#mel28tmp.df
str(mel28tmp.df)
summary(mel28tmp.df)
head(mel28tmp.df)

# take a look at it (check / fix factor levels)
genotype <- factor(mel28tmp.df$genotype,levels = c("WT","A","A;B"))
#genotype
mel28.df <- data.frame(genotype, 
                     replicate = mel28tmp.df$replicate, 
                       brood_size = mel28tmp.df$brood_size, 
                       fertilized = mel28tmp.df$fertilized)
#mel28.df
str(mel28.df)
summary(mel28.df)
head(mel28.df)

```


# Q1: Brood size

For this first part, we will be looking just at the ***brood sizes*** in the wild-type N2 strain (WT), in single mutants (A), and in double mutants (A;B).

### a) Strip chart / boxplot

Plot the brood size data, including the individual data points. For readability, make sure that the WT is the leftmost boxplot, followed by the single mutant and then the double mutant.

```{r}
ggplot(mel28.df, aes(x = genotype, y = brood_size, color = genotype)) +
  geom_jitter() +
  geom_boxplot() +
  labs(x = "Wild type(WT)  single mutant(A)  double mutant(A;B)") +
  ggtitle("*C.elegans* gene called *mel-28*") +
  theme_classic()

```

### b) Histograms

Use histogram plots to visualize the distributions. and perform an appropriate statistical test to determine if the measurements from the different groups are normally distributed.  

```{r}
# Wild type
mel28wt.df <- filter(mel28.df, genotype == "WT")
head(mel28wt.df)
wt.histo = ggplot(mel28wt.df, aes(x = brood_size)) +
  geom_histogram(fill = "firebrick", color = "black", binwidth = 3) +
  #labs(x = "Wild type(WT)  single mutant(A)  double mutant(A;B)") +
  ggtitle("C.elegans mel-28 (wild type)") +
  theme_classic()

wt.qq <- ggplot(mel28wt.df, aes(sample = brood_size)) +
  geom_qq() +
  geom_qq_line() +
  labs(y = "brood_size") +
  ggtitle("Q-Q plot (wild type)") +
  theme_classic()

library(ggpubr)
ggarrange(wt.histo, wt.qq, nrow=1)

t.test(mel28wt.df$brood_size)

# A single mutant 
mel28a.df <- filter(mel28.df, genotype == "A")
head(mel28a.df)
a.histo = ggplot(mel28a.df, aes(x = brood_size)) +
  geom_histogram(fill = "firebrick", color = "black", binwidth = 3) +
  #labs(x = "Wild type(WT)  single mutant(A)  double mutant(A;B)") +
  ggtitle("C.elegans mel-28 (single mutant)") +
  theme_classic()

a.qq <- ggplot(mel28a.df, aes(sample = brood_size)) +
  geom_qq() +
  geom_qq_line() +
  labs(y = "brood_size") +
  ggtitle("Q-Q plot (single mutant)") +
  theme_classic()

ggarrange(a.histo, a.qq, nrow=1)

t.test(mel28a.df$brood_size)

# A;B double mutant 
mel28ab.df <- filter(mel28.df, genotype == "A;B")
head(mel28ab.df)
ab.histo = ggplot(mel28ab.df, aes(x = brood_size)) +
  geom_histogram(fill = "firebrick", color = "black", binwidth = 3) +
  #labs(x = "Wild type(WT)  single mutant(A)  double mutant(A;B)") +
  ggtitle("C.elegans mel-28 (double mutant)") +
  theme_classic()

ab.qq <- ggplot(mel28ab.df, aes(sample = brood_size)) +
  geom_qq() +
  geom_qq_line() +
  labs(y = "brood_size") +
  ggtitle("Q-Q plot (double mutant)") +
  theme_classic()

ggarrange(ab.histo, ab.qq, nrow=1)

t.test(mel28ab.df$brood_size)

```

### c) ANOVA assumptions

In order to proceed with ANOVA, what two requirements should the data fulfill?

```{r eval=FALSE}
# your answer here
"Like t-tests, ANOVA assumes that the distributions of the samples are relatiely normal, and also that their variances are similar."
```

### d) Check for normality

Perform statistical tests to determine whether the data are normally distributed. (You may find it easier to subset the data at this point.)

```{r}
ggarrange(wt.qq, a.qq, ab.qq, nrow=1)

```


### e) Check for homoscedasticity

Determine if the variation is the same between the groups. This is called ***"homoscedasticity"***.

+ First, use the `var.test()` function to make pairwise comparisons between groups.
+ Then, use `bartlett.test()` to perform Bartlett's test on all of the groups at once.

```{r}
# var.test
vwt = c(mel28wt.df$brood_size)
va  = c(mel28a.df$brood_size)
vab = c(mel28ab.df$brood_size)

var.test(vwt,va)
var.test(vwt,vab)
var.test(va,vab)


# bartlett.test
#brood_size <- data.frame(mel28wt.df$brood_size, mel28a.df$brood_size, mel28ab.df$brood_size)
anova_mat = cbind(vwt, va, vab)
brood_size <- data.frame(anova_mat)

str(brood_size)

bartlett.test(brood_size)

```


What is the test statistic used by `var.test()`? What is the value of the statistic when the null hypothesis is true?

```{r eval=FALSE}
# your answer here
"The test statistic is p-value. Since the p-value is never less than 5%, the null hypotheses are all suspended and the variances among the three groups are considered equal."
```


What distribution does Bartlett's test statistic follow?

```{r eval=FALSE}
# your answer here
"Since the p-value is 12.5%, the null hypothesis is suspended and the variance among the three groups is considered to be equal."
```


Are the assumptions for performing ANOVA met for this dataset?

```{r eval=FALSE}
# your answer here
"The Q-Q plot shows that the distribution of the samples is relatively normal, and the p-values of var.test and bartlett.test are more than 5%, so we can suspend the null hypothesis and assume that the variances are similar."
```


# Q2: Sum of Squares and F-statistic  

### a) SSE and SSG

Calculate the sum of squares for $SS_{error}$ and $SS_{group}$ (you may use either base R methods or dplyr, as you prefer). Recall the formulas:

$$SS_{total} = SS_{error}+SS_{group}$$ 
$$SS_{error} = \sum_{i}\sum_{j}(Y−\overline{Y}_i)^{2}$$    
$$SS_{group} = \sum_{i}n_{i}(\overline{Y}_i−\overline{Y})^{2}$$
```{r}
# overall mean of the data
anova_mat_mean = mean(anova_mat)

# total variation = sum of squared deviations
#                   of each data point from theoverall mean
SST = sum((anova_mat - anova_mat_mean)**2)
SST

# total degrees of freedom = (# of data points) - 1
SST_df = length(anova_mat)-1
SST_df


# SS_error
anova_mat_col_mean = colMeans(anova_mat)
anova_mat_col_mean

SS_error=0
for (i in 1:nrow(anova_mat)) {
  SS_error = SS_error + sum((anova_mat[i,] - anova_mat_col_mean)**2 )
}
SS_error

## SS_group
SS_group = 0
for ( i in 1:length(anova_mat_col_mean)) {
  SS_group = SS_group + (nrow(anova_mat)*(anova_mat_col_mean[i]-anova_mat_mean)^2)
}
SS_group

SS_total = SS_error + SS_group
SS_total

```

### b) F-statistic and p-value

Calculate the F-statistic and the p-value using the `pf() function.` Recall that:

$$F=\frac{MS_{groups}}{MS_{error}} = \frac{SS_{groups}/df_{groups}}{SS_{error}/df_{error}}$$

```{r}
# degrees of freedom for SS_error
SS_error_df = ncol(anova_mat)*(nrow(anova_mat)-1)
SS_error_df

# degrees of freedom for SS_groups
SS_group_df = ncol(anova_mat)-1
SS_group_df

# F-statistic
MS_group = SS_group/SS_group_df  # (224667.6 /2)
MS_group
MS_error = SS_error/SS_error_df  # (41238.43/87)
MS_error  
Fstat = MS_group / MS_error
Fstat

# p-value using CDF for F-statistic

# p-value - note that df(between) comes before df(within)
#pf(Fstat, 2, 6, lower.tail = F)  # df1 = df(B) = 2; df2 = df(W) = 6 

pvalue = pf(Fstat, SS_group_df, SS_error_df, lower.tail = F)  # df1 = df(group) = 2; df2 = df(error) = 87
pvalue

```


# Q3: Planned and Unplanned ANOVA

### a) Planned vs. Unplanned

Explain whether this experiment should be treated as a PLANNED or an UNPLANNED dataset. How would the analysis differ between these two scenarios?

```{r eval=FALSE}
# your answer here
"This experiment should be treated as a planned dataset because a planned comparison is a comparison between means identified as being of crucial interest during the design of the study. Based on the results of Q1, we can assume that the dispersion is maintained. As for normality, the qq plot suggests that normality is maintained. Therefore, this experiment should be conducted as a planned experiement. In the case of a planned experiment, the lm function and the annova function are used. In the case of an unplanned experiment, if the variances are considered equal, use the aov function and the Tukey-Kramer function.  In the case of an unplanned experiment, if the variances are unequal variances, use the one way function."
```


### b) Planned experiment

Assume the data is a planned experiment. Use the `lm()` function to perform the analysis. 

First, use the `anova()` function on the results of of the `lm()` function to look at the overall result. *Note: you can use the special notation `$"Pr(>F)" to get the exact p-value from the `anova()` function.*

```{r}
library(reshape2)

# we use the melt function to reshape the data frame into three columns:
# Var1 = the three groups, indexed as 1, 2, 3
# Var2 = the three groups, indexed by their variable name
# value = the value of each data point
#head(anova_mat)
anova_mat.melt = melt(anova_mat, value.name = "brood_size" )
head(anova_mat.melt)  # look at this new data structure

# anova for lm of brood_size ~ genotype
#anova_lm = lm(value ~ Var2, data = anova_mat.melt)

anova_lm = lm(brood_size ~ Var2, data = anova_mat.melt)
#anova_lm
anova(anova_lm)

```

How do the $SS_error$, $SS_group$, $MS_error$, $MS_group$, $Fstat$, and $p$-value compare to the ones you calculated by  hand?

```{r eval=FALSE}
# your answer here
"These should be exactly the same."
SS_error
SS_group
MS_error
MS_group
Fstat
pvalue
"Except for p-value, the results from the anova function were the same within rounding error.
The p-value from the pf function of the F test and the Pr(>F) value from the anova function were not the same."

```

Now, use the `summary()` function on the results of the the linear model.

```{r}
summary(anova_lm)
```

What do the different parts of the `summary()` output tell you? What is R-squared and what does it mean?

```{r eval=FALSE}
# your answer here
"For wild type, both va and vab mutants are considered important because Pr(>{t{)) are both 2e-16. Multiple R-squared: 0.8449 is the coefficient of determination (contribution rate) of the single regression analysis, and it is close to 1, so we can say that it fits well. Adjusted R-squared: 0.8413 is the coefficient of determination for multiple regression analysis, adjusted for the degrees of freedom, which is also 0.8413, so we can say that it fits well."
""
```

Is the model significant overall? How about the different groups: are they significantly different from the control?

```{r eval=FALSE}
# your answer here
"Overall, this model is useful because the coefficient of determination is 0.84 for both wild type controls.
Since the p-value of Coefficients Pr(>|t|) is 2e-16 for single mutant and double mutant, we can say that both models are useful."
"
```


### c) Unplanned experiment

Now assume the data are from an unplanned experiment. Use the `aov()` function to perform the analysis, and then use the `tukeyHSD()` function on the results of `aov()`.

```{r}
# look at the result of the ANOVA command `aov`
# the formula syntax analyzes the values in response to the factors (groups a,b,c)
#anova_mat.melt
res_aov <- aov(anova_mat.melt$brood_size ~ anova_mat.melt$Var2)
res_aov

# summary of the aov model with F-stat and p-value
summary(res_aov)
```

```

Use the `tukeyHSD()` function on the results of `aov()` to perform the Tukey-Kramer test to look at all pairwise comparisons.

```{r}
TukeyHSD(res_aov)
```

What does Tukey's HSD test do? What do these results tell you? What is the biological interpretation of these results?

```{r eval=FALSE}
# your answer here
"The TukeyHSD test compares the mean of all treatments with the mean of all other treatments. p adjusted is 0 for all, so the results are considered to be significantly different, so this experiment was considered to be useful."

```


### d) Residuals

Once you have performed an ANOVA, you can also check your assumption of normality by checking to see if the ANOVA residuals are normally distributed. 

+ Do this by first assigning the results of your `aov()` function to a variable (e.g. `res_aov`.
+ Then, make a histogram of the residuals, which can be found in `res_aov$residuals`.
+ Finally, perform a test for normality on the residuals.

```{r}
#str(res_aov)
head(res_aov$residuals)

aov_res.histo <- ggplot(res_aov, aes(x = res_aov$residuals)) +
  geom_histogram(fill = "firebrick", color = "black", binwidth = 1) +
  ggtitle("aov residuals") +
  theme_classic()

aov_res.qq <- ggplot(res_aov, aes(sample = res_aov$residuals)) +
  geom_qq() +
  geom_qq_line() +
  labs(y = "res_aov$residuals") +
  ggtitle("Q-Q plot (aov residuals)") +
  theme_classic()

library(ggpubr)
ggarrange(aov_res.histo, aov_res.qq, nrow=1)

# normally test
shapiro.test(res_aov$residuals)

```


### e) ANOVA for unequal variances

If the data look normal, but the variances are unequal, what kind of ANOVA could you do instead? *Hint: what kind of $t$-test would you use in this case?*

```{r eval=FALSE}
# your answer here
"A Welch's version of ANOVA oneway.test()."
```

Perform this test below. Also extract the exact $p$-value from the test.

```{r}
oneway.test(brood_size ~ Var2, data = anova_mat.melt, var.equal = FALSE)
```

How does the $p$-value compare with the ANOVA you performed above? Explain.

```{r eval=FALSE}
# your answer here
"The result was p-value < 2.2e-16. As a result, the p-value this time is the same value."
```


# Q4: Fertilization phenotype

Now we will look at the fertilization phenotype. 

### a) Percent fertilization

+ Add a column to your original data frame containing the ***percent fertilization***.
+ Take a look at the percent fertilization using a stip chart / boxplot (as you did for Q1).

```{r}
# add percent fertilization column
mel28pf.df <- mel28.df %>%
               mutate(pfertilized = fertilized * 100 / brood_size )
                
head(mel28pf.df)
str(mel28pf.df)
summary(mel28pf.df)

# plot it
ggplot(mel28pf.df, aes(x = genotype, y = pfertilized, color = genotype)) +
  geom_jitter() +
  geom_boxplot() +
  labs(x = "Wild type(WT)  single mutant(A)  double mutant(A;B)") +
  labs(y = "Percent fertilization") +
  ggtitle("*C.elegans* gene called *mel-28*") +
  theme_classic()

```


### b) Check assumptions for ANOVA

Perform the appropriate tests to check whether you can perform an ANOVA on these data and draw histograms to visualize the distributions. (You may again find it useful at this point to subset the data by group.)

```{r}
mel28pfwt.df <- filter(mel28pf.df, genotype == "WT")
head(mel28pfwt.df)
mel28pfa.df <- filter(mel28pf.df, genotype == "A")
head(mel28pfa.df)
mel28pfab.df <- filter(mel28pf.df, genotype == "A;B")
head(mel28pfab.df)

# test for assumptions

t.test(mel28pfwt.df$pfertilized)
t.test(mel28pfa.df$pfertilized)
t.test(mel28pfab.df$pfertilized)

# var.test
vpfwt = c(mel28pfwt.df$pfertilized)
vpfa  = c(mel28pfa.df$pfertilized)
vpfab = c(mel28pfab.df$pfertilized)

var.test(vpfwt,vpfa)
var.test(vpfwt,vpfab)
var.test(vpfa,vpfab)

# bartlett.test
#brood_size <- data.frame(mel28wt.df$brood_size, mel28a.df$brood_size, mel28ab.df$brood_size)
anova_pf_mat = cbind(vpfwt, vpfa, vpfab)
pfertilized_size <- data.frame(anova_pf_mat)

str(pfertilized_size)

bartlett.test(pfertilized_size)


# histograms

# Wild type
pfwt.histo = ggplot(mel28pfwt.df, aes(x = pfertilized)) +
  geom_histogram(fill = "firebrick", color = "black", binwidth = 3) +
  #labs(x = "Wild type(WT)  single mutant(A)  double mutant(A;B)") +
  ggtitle("mel-28 (wild type)") +
  theme_classic()

pfwt.qq <- ggplot(mel28pfwt.df, aes(sample = pfertilized)) +
  geom_qq() +
  geom_qq_line() +
  labs(y = "Percent fertilization") +
  ggtitle("Q-Q plot (wild type)") +
  theme_classic()

library(ggpubr)
ggarrange(pfwt.histo, pfwt.qq, nrow=1)


# A single mutant 
pfa.histo = ggplot(mel28pfa.df, aes(x = pfertilized)) +
  geom_histogram(fill = "firebrick", color = "black", binwidth = 3) +
  #labs(x = "Wild type(WT)  single mutant(A)  double mutant(A;B)") +
  ggtitle("mel-28 (single mutant)") +
  theme_classic()

pfa.qq <- ggplot(mel28pfa.df, aes(sample = pfertilized)) +
  geom_qq() +
  geom_qq_line() +
  labs(y = "Percent fertilization") +
  ggtitle("Q-Q plot (single mutant)") +
  theme_classic()

ggarrange(pfa.histo, pfa.qq, nrow=1)


# A;B double mutant 
pfab.histo = ggplot(mel28pfab.df, aes(x = pfertilized)) +
  geom_histogram(fill = "firebrick", color = "black", binwidth = 3) +
  #labs(x = "Wild type(WT)  single mutant(A)  double mutant(A;B)") +
  ggtitle("mel-28 (double mutant)") +
  theme_classic()

pfab.qq <- ggplot(mel28pfab.df, aes(sample = pfertilized)) +
  geom_qq() +
  geom_qq_line() +
  labs(y = "Percent fertilization") +
  ggtitle("Q-Q plot (double mutant)") +
  theme_classic()

ggarrange(pfab.histo, pfab.qq, nrow=1)


#ggarrange(pfwt.qq, pfa.qq, pfab.qq, nrow=1)
#ggarrange(pfwt.histo, pfa.histo, pfab.histo, nrow=1)

```

Do these data meet the assumptions required for ANOVA? If not, what alternative tests could you perform? Explain the conditions under which either test would be appropriate.

```{r eval=FALSE}
# your answer here
"Since the normality assumption of ANOVA is not met, the assumptions required for ANOVA does not met. Therefore, the nonparametric alternative to single-factor ANOVA such as the Kruskal-Wallis test could be performed. The conditions under which the Kruskal-Wallis test would be appropriate is the following: 1. All group samples are random samples from the corresponding populations, 2. To use Kruskal-Wallis as a test of differences among populations in means or medians, the distribution of the variable must have the same shape in every population."
```

### c) Statistical test

Perform an appropriate alternative to ANOVA for these data.

```{r}
kruskal.test(x=list(vpfwt, vpfa, vpfab))

```
 
 
# Q5: Error, Power, and Sample size

Recall that the power is $1−\beta$, where $\beta$ is the Type II error. We can calculate the power of the ANOVA test using the command `power.anova.test()`, which is contained in the base `stats` package. The arguments for the command are:

+ **groups** = the number of groups in the dataset  
+ **n** = the number of observations per group  
+ **between.var** = between-group variance, $SS_{group}$
+ **within.var** = within-group variance, $SS_{error}$  
+ **sig.level** = significance cutoff $\alpha$ (Type I error)  
+ **power** = power of the test ($1−\beta = 1$ - Type II error)  

Given all of the arguments except for one, this function will return a value for the missing argument.

### a) Power of ANOVA for this dataset

Given the data that we have been provided and the $p$-value we obtained for the `brood_size`, what is the power of our dataset, given a Type I error rate (significance cutoff) of $\alpha=0.05$?

```{r}

# first, check the documentation
help(power.anova.test)

str(anova_mat)
summary(anova_mat)
ncol = ncol(anova_mat)
ncol
nrow = nrow(anova_mat)
nrow
# compute the power
power <-power.anova.test(groups= ncol, 
                 n= nrow, 
                 within.var= SS_error, 
                 between.var= SS_group, 
                 power=NULL,
                 sig.level= 0.05)
power

power$power
"The power is 100%."

```

### b) Sample size

If we would like to achieve a power of 95% with a Type I error rate of $\alpha=0.05$, how many observations for each group would we need? 

```{r}

# compute the required sample size
res <- power.anova.test(groups= ncol, 
                 n=NULL, 
                 within.var= SS_error, 
                 between.var= SS_group, 
                 power=0.95,
                 sig.level= 0.05)
res
str(res)

# sample size needed = 
round(res$n)

power.anova.test(groups= ncol, 
                 n=NULL, 
                 within.var= SS_error, 
                 between.var= SS_group, 
                 power=1,
                 sig.level= 0.05)

```

How do you feel about this result?

```{r eval=FALSE}
# your answer here
"If power=95%, the sample size should be 3, but I think it is too small. If power=99%, the sample size should be 3.27, but I also think it is too small. Therefore, when I use power=100%, it says that the sample size should be 10000. It seems that the amount of sample size required is quite different between 95% and 100% power."
```

### c) Effect size

The ratio of the between-groups variation to the within-groups variation ($SS_{group}/SS_{error}$) gives us an approximate effect size.

The `brood_size` data here has a pretty big effect size, and we have a lot of power because of this. 

If the effect size were 10 times smaller, how many animals would we need to get a power of 95% at a Type I error threshold of 5%?

```{r}
approximate = SS_group / SS_error
approximate
SS_group0.1 = SS_group / 10
SS_group0.1 / SS_error

power <- power.anova.test(groups= ncol, 
                 n=NULL, 
                 within.var= SS_error, 
                 between.var= SS_group0.1, 
                 power=0.95,
                 sig.level= 0.05)
power
str(power)
n = ceiling(power$n) 
n
"If we reduce the effect size by a factor of 10, we need a sample size of 16."

```

<!-- That's it! Yay! Check to see if your file knits and then send this off! -->

<!-- Note: if you don't have LaTeX installed, or you had problems installing it, then the file may not knit. In that case, type `rm(list = ls())` in the console and then try running the entire file again to make sure that all of your final data structures are what you think they are. -->
