---
title: "Homework 7: Hypergeometric test and line plots"
author: "Dylan Fitzmaurice"
date: "Due 10/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## 1) Gene set overlap

A recent study, [***Genetically engineered cerebral organoids model brain tumor formation*** (Bian et al., *Nat Meth* 2018)](https://www.nature.com/articles/s41592-018-0070-7),
created organoid models of two brain tumor types (primitive neuroectodermal
tumors and glioblastoma) using CRISPR to generate mutations in known oncogenes. 
The two conditions were generated by MYC oncogene overexpression, *MYC^OE^* (CNS-NET), and knockouts of several genes including *PTEN* and *P53* (GBM).

Differences in gene expression between two tumor models were compared with controls
and were found to differ in the sets of genes that were mis-regulated. 
The researchers first showed that the two organoid tumor models seem to show quite different
gene expression patterns using **PCA** (principal components analysis) of the top 500
genes with the highest variability compared with controls (see [**Figure 3a,b**](https://www.nature.com/articles/s41592-018-0070-7/figures/3)). 
We will go over PCA later in the course.

Next, they performed **hypergeometric tests** to ask whether all of the genes that 
were significantly **up- or down-regulated** in the two models (in comparison with 
controls) showed less overlap that expected by random chance (see [**Supplementary Figure 3**](https://www.nature.com/articles/s41592-018-0070-7/figures/9)).

If so, this would support the idea that divergent gene programs are misregulated 
in the two models.

Based on the PCA analysis (**Figure 3a**), differentially expressed genes could be separated into two different groups corresponding to the two organoid tumor models: Cluster 2 (*MYC^OE^*) and Cluster 3 (GBM).

![](HW7_data/Bian_Fig3a.png){width=50%}

**Fig. S3** shows Venn diagrams of the gene set overlaps between Clusters 2 and 3:

![](HW7_data/Bian_FigS3a.png){width=50%}

Your question is whether the differentially expressed genes in these two clusters overlap by **less** than expected by chance. Here we will focus on just the **up-regulated genes**. How will you set up the problem?


### a) Expected gene set overlap based on independence

In total, 4034 genes were up-regulated in at least one of the organoid tumor models (vs. controls). The rest of the numbers you will need are shown in the Venn diagrams in Fig. S3. A framework for organizing the data has been set up below to help get you started.

```{r, collapse=T}
## Up-regulated genes ======================================================== #
## 4034 genes up-regulated in either experiment (vs control)

ol.obs =  92      # overlap
A = 2155 + 92     # total size of Cluster 2 (Set A = bigger set)
B = 203 + 92      # total size of Cluster 3 (Set B = smaller set)
N = 203 + 92 + 2155          # total genes up-regulated in both experiments
# 
# # What is the expected overlap based on the null hypothesis of independence?
 ol.exp = A * B / N 
 ol.exp
```


### b) Hypergeometric test

Find a p-value for the observed overlap with a hypergeometric test using `dhyper` and `pyhper`. Remember, you are looking for less overlap than expected between the two sets (is this the lower tail or the upper tail?).

First, look up the documentation on these functions.
```{r}
ol.obs = 92

dhyper(ol.obs, B, N - B, A) #lower tail = TRUE, because looking for less overlap

phyper(ol.obs, B, N - B, A)
```

Here are some additional tips to help you figure out how to parameterize the functions:

+ $x$: this is the observed overlap
+ $m$: pick one gene set, call this Set A
+ $n$: this is the total number of genes NOT in Set A (out of all the up-regulated genes)
+ $k$: the other set (Set B)
  +  Note that the maximum possible size of the overlap would be the total size of the smaller gene set (which cluster is that here?)
  + It does not really matter which set you choose to use for $m$ or $k$; the p-value will be the same either way.

```{r, collapse=T}
## p-value using hypergeometric test ========================================= #

# using CDF function
phyper(ol.obs, B, N - B, A)

# using PDF function
dhyper(ol.obs, B, N - B, A)

```


### c) Fisher's Exact Test

The hypergeometric test is equivalent to a one-tailed Fisher's test (but it is 
actually more efficient in R). Use a Fisher's test to make the same comparison as above. Here are some helpful hints:

+ You want to perform a one-sided test for more extreme values than the ones observed, given all possible combinations of values "conditioned on fixed margins" (which tail are you looking for here?).
+ Make a contingency table: orientation is arbitrary, but by convention put the categories "of interest" first.
  + Put the overlap in the top left cell (*a*, a.k.a. $x_{11}$).
  + Put the remainder of the A and B sets (minus the overlap) in the right (*b*, $x_{12}$) and bottom left (*c*, $x_{21}$) cells.
  + Put the remainder of the up-regulated genes in (*d*, $x_{22}$).

```{r, collapse=T}
## with Fisher's exact test ================================================== #
a = ol.obs                              #a
A_not_B = A - ol.obs                    #b
B_not_A = B - ol.obs                    #c
remainder_up =  N - B - A + ol.obs      #d
contingency.table = rbind(c(a, B_not_A),
                          c(A_not_B, remainder_up))
rownames(contingency.table) = c("overlap","not overlapping")
colnames(contingency.table) = c("A","B")
contingency.table
```

### d) How do the p-values compare?

```{r}
# your answer here
fisher.test(contingency.table)$p.value
#same p-values
```


## 2) Line plots: Mean, SD, SEM

Please read the short article *Error bars (Nat Meth 2013)* provided with this assignment.

### a) What is the difference between the standard error (SEM) of the mean and standard deviation?  
```{r eval=FALSE}
# your answer here
#The SEM is the standard deviation but its divided by the square root of the number of samples
```

### b) What are some common misconceptions about interpreting error bars?
```{r eval=FALSE}
# your answer here
#A gap between error bars does not ensure significance, and overlap does not necessarily 
#rule it out
```

## 3) Cancer metabolism

In the paper [***Metabolic competition in the tumor microenvironment is a driver of cancer progression*** (Chang et al., *Cell* 2015)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4864363/), the authors use mouse models to demonstrate that in cancers, T cells are metabolically restricted by tumor glucose consumption, ultimately allowing tumor progression. The authors use line graphs in **Figure 4B**:

![](HW7_data/Chang_Fig4B.png){width=60%}

### a) What question were the researchers trying to answer in this Figure?
```{r eval=FALSE}
# your answer here (one sentence)
#Whether specific antibodys tested could kill tumors (decrease tumor diameter)
```

### b) How many replicates were performed, and what do the error bars represent?
```{r eval=FALSE}
# your answer here (1-2 sentences)
#3 independent experiments, and the error bars represent SEM.
```

### c) Do you think this an appropriate way to represent the data? Why or why not, and how would you try to represent them?
```{r eval=FALSE}
# your answer here
#I think its fine to show the data like this because its three independent experiments and it shows
#clear differences in the control and treatment groups. Though I would use standard deviation 
#because I think its slightly more intuitive and becuase the sample size is so small, only 3.
```
    

## 4) Spindle dynamics in evolution

The paper [***Stoichiometric interactions explain spindle dynamics and scaling across 100 million years of nematode evolution*** (Farhadifar et al., *eLife* 2020)](https://elifesciences.org/articles/55877) explores spindle dynamics in *C. elegans* using a combination of imaging methods and QTL mapping of intercross lines. Below is reproduced Figure 3 from this article:

![](HW7_data/Farhadifar_Fig3.jpg){width=80%}

### a) What question were the researchers trying to answer in this figure?
```{r eval=FALSE}
# your answer here (1-2 sentences)
#Whether spindle length is effected in the mutants tested. 
```

### b) Panels C and D

About how many data points are there for each line? What do the error bars represent? Would you change anything about the way the data are represented?
```{r eval=FALSE}
# your answer here (2-3 sentences)
#Its unclear how many points where used.  I would include the N and also include the 95%
#confindence interval becuase the error bars (SEM) do not illustrate the breath of the data well. 
```

### c) Panels E and F

What is being plotted? What do the shaded areas represent, and why do you think the researchers chose to display the variation in their measurements in this way? Would you have done anything differently?
```{r eval=FALSE}
# your answer here (~2-3 sentences)
#Spindle length versus time. The shaded area represents standard deviation. I think the researchers 
#choose to display the variation this way because the data is very consistent, I would not change anything.
```


## 5) Line plots with SD or SEM

How would you plot similar graphs in R showing SD or SEM? The dataset "HW7_data.csv" contains eight replicate measurements across 20 timepoints (0-190 seconds) for a control and a treatment condition. The data are the raw (non-normalized) values used to generate the plots in Figure 6A from 
[Cipriani et al., eLife 2021](https://elifesciences.org/articles/60833).

### a) Calculate the mean, SD, SEM

Load the dataset and use the `dplyr` package to reformat it as follows:

+ Group the data by treatment and time (hint: use `group_by()`).
+ Add 3 new columns to the data frame containing group summaries for the mean, SEM, and SD (hint: use `summarise()`).
+ Add 4 new columns containing the upper and lower limits for the SEM and the SD.
  
```{r}
library(dplyr)
HW7_data <- read.csv("~/R/Biostats/Week_7/HW7_data.csv")
head(HW7_data)

HW7_grouped_data = HW7_data %>% group_by(TREATMENT, time) %>% summarise(mean(Values)) 
HW7_grouped_SEM = HW7_data %>% group_by(TREATMENT, time) %>% summarise(sd(Values)/sqrt(8)) 
HW7_grouped_SD = HW7_data %>% group_by(TREATMENT, time) %>% summarise(sd(Values)) 

HW7_grouped_data$SEM = HW7_grouped_SEM[,3]
HW7_grouped_data$SD= HW7_grouped_SD[,3]

HW7_grouped_data$SE_upper = HW7_grouped_data$`mean(Values)`+ HW7_grouped_data$SEM
HW7_grouped_data$SE_lower = HW7_grouped_data$`mean(Values)`- HW7_grouped_data$SEM

HW7_grouped_data$SD_upper = HW7_grouped_data$`mean(Values)`+ HW7_grouped_data$SD
HW7_grouped_data$SD_lower = HW7_grouped_data$`mean(Values)`- HW7_grouped_data$SD
```
    

### b) Line plot with discrete error bars showing SD

Use `ggplot2` to create a line graph to plot the mean, with discrete error bars representing the standard deviation.

+ Map the data to time (x-axis) and mean (y-axis), and use color to indicate the treatment.
+ Use a line for the geom layer.
+ Add the error bars using `geom_errorbar()` (look this up to see how to add the upper and lower boundaries). Don't forget to map the color to the treatment.
+ Add axis labels for the time (in seconds) and the values (as "Relative fluorescence").

```{r}
library(ggplot2)

my.ggplot = ggplot(data = HW7_grouped_data,
                     mapping = aes(x = time,
                     y = HW7_grouped_data$`mean(Values)`,
                     group = TREATMENT,
                     colour = TREATMENT,
                     linetype=TREATMENT))+
                     geom_line()+
                     geom_point()+
                     labs(x = "Time (s)", y = "Relative Fluorescence")+
                     ylim(c(0,1.3))
my.ggplot

#my.ggplot + geom_errorbar(x = HW7_grouped_data , ymin = HW7_grouped_data$SD_lower, ymax = HW7_grouped_data$SD_upper)
#Not sure why I can't get the errorbar code working
```

### c) Line plot with shaded regions showing SEM

Use `ggplot2` to create a line graph to plot the mean, with a shaded area representing the standard error of the mean. This plot will use almost the exact same code as the last graph, except you will use `geom_ribbon()` to display the upper and lower bounds of the SEM.
      
```{r}

```


### d) Which representation do you think is most effective for these data? What would you choose to do?
```{r}
# your answer here (1-2 sentences)
#Its hard to say since I didn't get the code working correct but theres only 8 data points per time point so the SD and SEM may not be too different from one another unless there was a lot of variability in the samples.
```

