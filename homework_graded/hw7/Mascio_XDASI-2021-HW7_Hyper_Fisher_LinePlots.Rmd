---
title: "Homework 7: Hypergeometric test and line plots"
author: "Isabella Mascio"
date: "Due 10/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## 1) Gene set overlap

A recent study, [***Genetically engineered cerebral organoids model brain tumor formation*** (Bian et al., *Nat Meth* 2018)](https://www.nature.com/articles/s41592-018-0070-7),
created organoid models of two brain tumor types (primitive neuroectodermal
tumors and glioblastoma) using CRISPR to generate mutations in known oncogenes. 
The two conditions were generated by MYC oncogene overexpression, *MYC^OE^* (CNS-NET), and knockouts of several genes including *PTEN* and *P53* (GBM).

Differences in gene expression between two tumor models were compared with controls
and were found to differ in the sets of genes that were mis-regulated. 
The researchers first showed that the two organoid tumor models seem to show quite different
gene expression patterns using **PCA** (principal components analysis) of the top 500
genes with the highest variability compared with controls (see [**Figure 3a,b**](https://www.nature.com/articles/s41592-018-0070-7/figures/3)). 
We will go over PCA later in the course.

Next, they performed **hypergeometric tests** to ask whether all of the genes that 
were significantly **up- or down-regulated** in the two models (in comparison with 
controls) showed less overlap that expected by random chance (see [**Supplementary Figure 3**](https://www.nature.com/articles/s41592-018-0070-7/figures/9)).

If so, this would support the idea that divergent gene programs are misregulated 
in the two models.

Based on the PCA analysis (**Figure 3a**), differentially expressed genes could be separated into two different groups corresponding to the two organoid tumor models: Cluster 2 (*MYC^OE^*) and Cluster 3 (GBM).

![](HW7_data/Bian_Fig3a.png){width=50%}

**Fig. S3** shows Venn diagrams of the gene set overlaps between Clusters 2 and 3:

![](HW7_data/Bian_FigS3a.png){width=50%}

Your question is whether the differentially expressed genes in these two clusters overlap by **less** than expected by chance. Here we will focus on just the **up-regulated genes**. How will you set up the problem?


### a) Expected gene set overlap based on independence

In total, 4034 genes were up-regulated in at least one of the organoid tumor models (vs. controls). The rest of the numbers you will need are shown in the Venn diagrams in Fig. S3. A framework for organizing the data has been set up below to help get you started.

```{r, collapse=T}
## Up-regulated genes ======================================================== #
## 4034 genes up-regulated in either experiment (vs control)

ol.obs = 92             # overlap
A = 2155 + 92           # total size of Cluster 2 (Set A = bigger set)
B = 203 + 92            # total size of Cluster 3 (Set B = smaller set)
N = 4034                # total genes up-regulated in both experiments
# 
# # What is the expected overlap based on the null hypothesis of independence?
ol.exp = A*B/N
ol.exp
```


### b) Hypergeometric test

Find a p-value for the observed overlap with a hypergeometric test using `dhyper` and `pyhper`. Remember, you are looking for less overlap than expected between the two sets (is this the lower tail or the upper tail?).

First, look up the documentation on these functions.
```{r}
?dhyper
?phyper
#lower-tail
```

Here are some additional tips to help you figure out how to parameterize the functions:

+ $x$: this is the observed overlap
+ $m$: pick one gene set, call this Set A
+ $n$: this is the total number of genes NOT in Set A (out of all the up-regulated genes)
+ $k$: the other set (Set B)
  +  Note that the maximum possible size of the overlap would be the total size of the smaller gene set (which cluster is that here?)
  + It does not really matter which set you choose to use for $m$ or $k$; the p-value will be the same either way.

```{r, collapse=T}
## p-value using hypergeometric test ========================================= #

# using CDF function
phyper(ol.obs, m = A, n = N-A, k = B, lower.tail = TRUE)
# using PDF function
sum(dhyper(0:ol.obs, m = A, n = N-A, k = B))
```


### c) Fisher's Exact Test

The hypergeometric test is equivalent to a one-tailed Fisher's test (but it is 
actually more efficient in R). Use a Fisher's test to make the same comparison as above. Here are some helpful hints:

+ You want to perform a one-sided test for more extreme values than the ones observed, given all possible combinations of values "conditioned on fixed margins" (which tail are you looking for here?).
+ Make a contingency table: orientation is arbitrary, but by convention put the categories "of interest" first.
  + Put the overlap in the top left cell (*a*, a.k.a. $x_{11}$).
  + Put the remainder of the A and B sets (minus the overlap) in the right (*b*, $x_{12}$) and bottom left (*c*, $x_{21}$) cells.
  + Put the remainder of the up-regulated genes in (*d*, $x_{22}$).

```{r, collapse=T}
## with Fisher's exact test ================================================== #
contig_table <- matrix(data = c(ol.obs, A-ol.obs, B-ol.obs, N-A-B+ol.obs), nrow = 2, byrow = TRUE)
fisher.test(contig_table, alternative = "l")
```

### d) How do the p-values compare?

```{r}
# they are slightly different but they are both very small numbers
# hypergeom. - 1.001302e-18
# fisher - <2.2e-16
```


## 2) Line plots: Mean, SD, SEM

Please read the short article *Error bars (Nat Meth 2013)* provided with this assignment.

### a) What is the difference between the standard error (SEM) of the mean and standard deviation?  
```{r eval=FALSE}
# Standard deviation gives you the spread of the sample and predict the range of new samples (variation in data). Standard error of the mean shows the uncertainty of the mean and its dependency on sample size (error in your measurement).
```

### b) What are some common misconceptions about interpreting error bars?
```{r eval=FALSE}
# when sem error bars don't touch, it shows statistical significance
# sd bars show error in your measurement
# a gap doesn't ensure significance and an overlap doesn't rule it out
```

## 3) Cancer metabolism

In the paper [***Metabolic competition in the tumor microenvironment is a driver of cancer progression*** (Chang et al., *Cell* 2015)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4864363/), the authors use mouse models to demonstrate that in cancers, T cells are metabolically restricted by tumor glucose consumption, ultimately allowing tumor progression. The authors use line graphs in **Figure 4B**:

![](HW7_data/Chang_Fig4B.png){width=60%}

### a) What question were the researchers trying to answer in this Figure?
```{r eval=FALSE}
# Do these blockade antibodies affect the growth of tumors?
```

### b) How many replicates were performed, and what do the error bars represent?
```{r eval=FALSE}
# The error bars are the standard error of the mean. There were 3+ replicates per group.
```

### c) Do you think this an appropriate way to represent the data? Why or why not, and how would you try to represent them?
```{r eval=FALSE}
# no, it is very hard to determine that replicates were done and you cannot visualize the individual lines that aren't the p-isotype. I think it would be valuable to do a dotplot/boxplot with the same axes to actually see what is happening. Also, the color choices aren't good as the light blue is hard to see and likely is not colorblind friendly. 
```
    

## 4) Spindle dynamics in evolution

The paper [***Stoichiometric interactions explain spindle dynamics and scaling across 100 million years of nematode evolution*** (Farhadifar et al., *eLife* 2020)](https://elifesciences.org/articles/55877) explores spindle dynamics in *C. elegans* using a combination of imaging methods and QTL mapping of intercross lines. Below is reproduced Figure 3 from this article:

![](HW7_data/Farhadifar_Fig3.jpg){width=80%}

### a) What question were the researchers trying to answer in this figure?
```{r eval=FALSE}
# What are the mechanisms/loci that determine final spindle length?
```

### b) Panels C and D

About how many data points are there for each line? What do the error bars represent? Would you change anything about the way the data are represented?
```{r eval=FALSE}
# The error bars are standard error. I think there are 500 points per line based on the methods, but I couldn't find the actual number anywhere. I would use a violin plot instead of the dots because it is impossible to actually visualize the density of these dots. The sem is small compared the range of data, so it could be helpful to give values/p-values.
```

### c) Panels E and F

What is being plotted? What do the shaded areas represent, and why do you think the researchers chose to display the variation in their measurements in this way? Would you have done anything differently?
```{r eval=FALSE}
# The length of the spindles over time in the knockdown vs control. The shaded area is the standard deviation. There aren't individual discrete time points so error bars would be super on top of each other and unclear. If there are separate time points for the data, it would've been interesting to see dotplots to visualize the replicates.
```


## 5) Line plots with SD or SEM

How would you plot similar graphs in R showing SD or SEM? The dataset "HW7_data.csv" contains eight replicate measurements across 20 timepoints (0-190 seconds) for a control and a treatment condition. The data are the raw (non-normalized) values used to generate the plots in Figure 6A from 
[Cipriani et al., eLife 2021](https://elifesciences.org/articles/60833).

### a) Calculate the mean, SD, SEM

Load the dataset and use the `dplyr` package to reformat it as follows:

+ Group the data by treatment and time (hint: use `group_by()`).
+ Add 3 new columns to the data frame containing group summaries for the mean, SEM, and SD (hint: use `summarise()`).
+ Add 4 new columns containing the upper and lower limits for the SEM and the SD.
  
```{r}
library(dplyr)
data <- read.csv("./HW7_data/HW7_data.csv")
sum_table <- data %>% group_by(TREATMENT, time) %>% summarise(mean = mean(Values), sem = sd(Values)/sqrt(8), sd = sd(Values)) %>% mutate(ll_sem = mean - sem, ul_sem = mean + sem, ll_sd = mean - sd, ul_sd = mean + sd)

sum_table

```
    

### b) Line plot with discrete error bars showing SD

Use `ggplot2` to create a line graph to plot the mean, with discrete error bars representing the standard deviation.

+ Map the data to time (x-axis) and mean (y-axis), and use color to indicate the treatment.
+ Use a line for the geom layer.
+ Add the error bars using `geom_errorbar()` (look this up to see how to add the upper and lower boundaries). Don't forget to map the color to the treatment.
+ Add axis labels for the time (in seconds) and the values (as "Relative fluorescence").

```{r}
library(ggplot2)
ggplot(sum_table, aes(time, mean, col = TREATMENT)) +
  geom_line() +
  geom_errorbar(aes(ymin = ll_sd, ymax = ul_sd, col = TREATMENT)) +
  labs(x = "time in seconds", y = "Relative fluorescence")
```


### c) Line plot with shaded regions showing SEM

Use `ggplot2` to create a line graph to plot the mean, with a shaded area representing the standard error of the mean. This plot will use almost the exact same code as the last graph, except you will use `geom_ribbon()` to display the upper and lower bounds of the SEM.
      
```{r}
ggplot(sum_table, aes(time, mean, col = TREATMENT)) +
  geom_line() +
  geom_ribbon(aes(ymin = ll_sem, ymax = ul_sem, fill = TREATMENT), alpha = 0.5) +
  labs(x = "time in seconds", y = "Relative fluorescence")
```


### d) Which representation do you think is most effective for these data? What would you choose to do?
```{r}
# The standard error of the mean is most effective for these data because you can clearly see the difference in the control and the experiment lines. The standard deviation bars overlap in some cases and take up so much space that the data seem blurred.
```

