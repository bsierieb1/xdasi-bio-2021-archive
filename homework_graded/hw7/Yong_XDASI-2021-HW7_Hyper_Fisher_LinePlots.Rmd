---
title: "Homework 7: Hypergeometric test and line plots"
author: "Rita Levi-Montalcini [Luok Wen Yong]"
date: "Due 10/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## 1) Gene set overlap

A recent study, [***Genetically engineered cerebral organoids model brain tumor formation*** (Bian et al., *Nat Meth* 2018)](https://www.nature.com/articles/s41592-018-0070-7),
created organoid models of two brain tumor types (primitive neuroectodermal
tumors and glioblastoma) using CRISPR to generate mutations in known oncogenes. 
The two conditions were generated by MYC oncogene overexpression, *MYC^OE^* (CNS-NET), and knockouts of several genes including *PTEN* and *P53* (GBM).

Differences in gene expression between two tumor models were compared with controls
and were found to differ in the sets of genes that were mis-regulated. 
The researchers first showed that the two organoid tumor models seem to show quite different
gene expression patterns using **PCA** (principal components analysis) of the top 500
genes with the highest variability compared with controls (see [**Figure 3a,b**](https://www.nature.com/articles/s41592-018-0070-7/figures/3)). 
We will go over PCA later in the course.

Next, they performed **hypergeometric tests** to ask whether all of the genes that 
were significantly **up- or down-regulated** in the two models (in comparison with 
controls) showed less overlap that expected by random chance (see [**Supplementary Figure 3**](https://www.nature.com/articles/s41592-018-0070-7/figures/9)).

If so, this would support the idea that divergent gene programs are misregulated 
in the two models.

Based on the PCA analysis (**Figure 3a**), differentially expressed genes could be separated into two different groups corresponding to the two organoid tumor models: Cluster 2 (*MYC^OE^*) and Cluster 3 (GBM).

![](HW7_data/Bian_Fig3a.png){width=50%}

**Fig. S3** shows Venn diagrams of the gene set overlaps between Clusters 2 and 3:

![](HW7_data/Bian_FigS3a.png){width=50%}

Your question is whether the differentially expressed genes in these two clusters overlap by **less** than expected by chance. Here we will focus on just the **up-regulated genes**. How will you set up the problem?


### a) Expected gene set overlap based on independence

In total, 4034 genes were up-regulated in at least one of the organoid tumor models (vs. controls). The rest of the numbers you will need are shown in the Venn diagrams in Fig. S3. A framework for organizing the data has been set up below to help get you started.

```{r, collapse=T}
## Up-regulated genes ======================================================== #
## 4034 genes up-regulated in either experiment (vs control)

# ol.obs =  # overlap
# A =       # total size of Cluster 2 (Set A = bigger set)
# B =       # total size of Cluster 3 (Set B = smaller set)
# N =       # total genes up-regulated in both experiments
# 

ol.obs = 92
A = 2155 + 92  
B = 203 + 92
N = 4034

# # What is the expected overlap based on the null hypothesis of independence?
# ol.exp = 
# ol.exp

ol.exp = A * B / N
ol.exp

```


### b) Hypergeometric test

Find a p-value for the observed overlap with a hypergeometric test using `dhyper` and `pyhper`. Remember, you are looking for less overlap than expected between the two sets (is this the lower tail or the upper tail?).

First, look up the documentation on these functions.
```{r}
#lookup the function
?dhyper
?phyper
```

Here are some additional tips to help you figure out how to parameterize the functions:

+ $x$: this is the observed overlap
+ $m$: pick one gene set, call this Set A
+ $n$: this is the total number of genes NOT in Set A (out of all the up-regulated genes)
+ $k$: the other set (Set B)
  +  Note that the maximum possible size of the overlap would be the total size of the smaller gene set (which cluster is that here?)
  + It does not really matter which set you choose to use for $m$ or $k$; the p-value will be the same either way.

```{r, collapse=T}
## p-value using hypergeometric test ========================================= #

# using CDF function
phyper(ol.obs, B, N - B, A) #1.001302e-18

# using PDF function
#we want the "lower.tail"
sum(dhyper(0:ol.obs, B, N - B, A )) 
```


### c) Fisher's Exact Test

The hypergeometric test is equivalent to a one-tailed Fisher's test (but it is 
actually more efficient in R). Use a Fisher's test to make the same comparison as above. Here are some helpful hints:

+ You want to perform a one-sided test for more extreme values than the ones observed, given all possible combinations of values "conditioned on fixed margins" (which tail are you looking for here?).
+ Make a contingency table: orientation is arbitrary, but by convention put the categories "of interest" first.
  + Put the overlap in the top left cell (*a*, a.k.a. $x_{11}$).
  + Put the remainder of the A and B sets (minus the overlap) in the right (*b*, $x_{12}$) and bottom left (*c*, $x_{21}$) cells.
  + Put the remainder of the up-regulated genes in (*d*, $x_{22}$).

```{r, collapse=T}
## with Fisher's exact test ================================================== #
A.not.B = A-ol.obs
B.not.A = B-ol.obs
N.not.AB = N - B - A + ol.obs  # same as: N - B - A.not.B
contingency.table = rbind(c(ol.obs, A.not.B),
                          c(B.not.A, N.not.AB))
rownames(contingency.table) = c("Overlap","Set A")
colnames(contingency.table) = c("Set B","Others")
contingency.table
fisher.test(contingency.table, alternative="less")
fisher.test(contingency.table, alternative="less")$p.value #1.001302e-18

```

### d) How do the p-values compare?

```{r}
# the P-values are the same for the both the fisher's test and the hypergeometric test. 
```


## 2) Line plots: Mean, SD, SEM

Please read the short article *Error bars (Nat Meth 2013)* provided with this assignment.

### a) What is the difference between the standard error (SEM) of the mean and standard deviation?  
```{r eval=FALSE}
#Standard deviation measure the spread of the data in relation to the mean. 
#Standard error of the mean shows the dispersion of samples means around the population mean. It reflects the uncertainty of the measurement of the mean. 
```

### b) What are some common misconceptions about interpreting error bars?
```{r eval=FALSE}
# Standard deviation is the measurement of the spread of data around mean, it is NOT a measurement of the error in the measurement. 
# The view where "sem error bar overlap - no significant different" is incorrect - this is dependent on the sample size measured.  
# A common misconception about CIs is an expectation that a CI captures the mean of a second sample drawn from the same population with a CI% chance. Because CI position and size vary with each sample, this chance is actually lower. 
#The errors bar for small samples sizes are not always robust and may not be statistically informative. 
```

## 3) Cancer metabolism

In the paper [***Metabolic competition in the tumor microenvironment is a driver of cancer progression*** (Chang et al., *Cell* 2015)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4864363/), the authors use mouse models to demonstrate that in cancers, T cells are metabolically restricted by tumor glucose consumption, ultimately allowing tumor progression. The authors use line graphs in **Figure 4B**:

![](HW7_data/Chang_Fig4B.png){width=60%}

### a) What question were the researchers trying to answer in this Figure?
```{r eval=FALSE}
# The authors are trying to answer whether the different treatments (different colors) has an effect on the tumor diameter over time.  
```

### b) How many replicates were performed, and what do the error bars represent?
```{r eval=FALSE}
# For each treatment, there are 3 or more replicates. The error bar represents the standard error of the mean. 
```

### c) Do you think this an appropriate way to represent the data? Why or why not, and how would you try to represent them?
```{r eval=FALSE}
# NO , not a good way. 
# In terms of using the error bars, i think using the SEM is not very good as the sample size is very small, and the error bars are not informative. I will just plot the individual data points on the graph instead of representing using the error bars. 
```
    

## 4) Spindle dynamics in evolution

The paper [***Stoichiometric interactions explain spindle dynamics and scaling across 100 million years of nematode evolution*** (Farhadifar et al., *eLife* 2020)](https://elifesciences.org/articles/55877) explores spindle dynamics in *C. elegans* using a combination of imaging methods and QTL mapping of intercross lines. Below is reproduced Figure 3 from this article:

![](HW7_data/Farhadifar_Fig3.jpg){width=80%}

### a) What question were the researchers trying to answer in this figure?
```{r eval=FALSE}
# Is the variation in the final spindle length overtime affected by the genes(gpr-1, par-2) that are mapped to the QTL loci(QTL1, QTL2)?
```

### b) Panels C and D

About how many data points are there for each line? What do the error bars represent? Would you change anything about the way the data are represented?
```{r eval=FALSE}
# 500 for each QTL analysis, a lot of data points. 
#error bars represent standard error.
#I will plot a violin plot just to "spread out" the clumped/stacked points in the middle. 
```

### c) Panels E and F

What is being plotted? What do the shaded areas represent, and why do you think the researchers chose to display the variation in their measurements in this way? Would you have done anything differently?
```{r eval=FALSE}
# 
#Plotted: Change in length of spindle over time for control and knockdown experiments. 
#Shaded areas represent the standard deviation. 
#With Standard deviation, what you show is the spread of the sampled data around the mean, This way of showing the error bar will give you an idea of the magnitude of the sample?
#No, will not change it, this looks good enough. 

```


## 5) Line plots with SD or SEM

How would you plot similar graphs in R showing SD or SEM? The dataset "HW7_data.csv" contains eight replicate measurements across 20 timepoints (0-190 seconds) for a control and a treatment condition. The data are the raw (non-normalized) values used to generate the plots in Figure 6A from 
[Cipriani et al., eLife 2021](https://elifesciences.org/articles/60833).

### a) Calculate the mean, SD, SEM

Load the dataset and use the `dplyr` package to reformat it as follows:

+ Group the data by treatment and time (hint: use `group_by()`).
+ Add 3 new columns to the data frame containing group summaries for the mean, SEM, and SD (hint: use `summarise()`).
+ Add 4 new columns containing the upper and lower limits for the SEM and the SD.
  
```{r}
#library(dplyr)
HW7_data = read.csv("/Users/lwyong/Desktop/LW Yong NYU/Biostat 2021 Fall/Week 7 /HW7/XDASI-2021-HW7/HW7_data/HW7_data.csv", header = T)
head(HW7_data)

se <- function(x) sd(x)/sqrt(length(x))

library(dplyr)

HW7.data = HW7_data %>%
  group_by(TREATMENT,time) %>%
  summarise(mean = mean(Values), sd = sd(Values), SEM = se(Values)) %>%
  mutate (upper_sem = mean + SEM, lower_sem = mean - SEM, upper_sd= mean + sd, lower_sd = mean - sd)
HW7.data

```
    

### b) Line plot with discrete error bars showing SD

Use `ggplot2` to create a line graph to plot the mean, with discrete error bars representing the standard deviation.

+ Map the data to time (x-axis) and mean (y-axis), and use color to indicate the treatment.
+ Use a line for the geom layer.
+ Add the error bars using `geom_errorbar()` (look this up to see how to add the upper and lower boundaries). Don't forget to map the color to the treatment.
+ Add axis labels for the time (in seconds) and the values (as "Relative fluorescence").

```{r}
#library(ggplot2)
library(ggplot2)
#with SD for error bars
Q <- ggplot(data = HW7.data, 
       mapping = aes(x = time, y = mean))+
  geom_line(aes(col=TREATMENT)) +
  geom_errorbar(aes(ymin = lower_sd, ymax = upper_sd, col=TREATMENT), width = 5.0) +
  labs(x = "time(in seconds)", y = "Relative fluorescence")
Q

```


### c) Line plot with shaded regions showing SEM

Use `ggplot2` to create a line graph to plot the mean, with a shaded area representing the standard error of the mean. This plot will use almost the exact same code as the last graph, except you will use `geom_ribbon()` to display the upper and lower bounds of the SEM.
      
```{r}
R2 <- ggplot(data = HW7.data, 
       mapping = aes(x = time, y = mean))+
  geom_line(aes(col=TREATMENT)) +
  geom_ribbon(mapping=aes(x=time, ymin=lower_sem, ymax=upper_sem, fill=TREATMENT), alpha=0.5) +
  labs(x = "time(in seconds)", y = "Relative fluorescence")
R2
```


### d) Which representation do you think is most effective for these data? What would you choose to do?
```{r}
# the 1st graph is better, at least with SD error bars, you can tell the range/dispersion of the sampled data. At least you can tell if there is any sort of overlap between the control and treatment, although it might not show anything is statistically significant. This gives you a sense of the spread of the sampled data (control or treatment) and gives you an idea of the magnitude of the sampled data.
```

