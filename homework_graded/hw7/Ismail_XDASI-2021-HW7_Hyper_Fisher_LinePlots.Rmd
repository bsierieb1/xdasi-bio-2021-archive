---
title: "Homework 7: Hypergeometric test and line plots"
author: "Noha Ismail"
date: "Due 10/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## 1) Gene set overlap

A recent study, [***Genetically engineered cerebral organoids model brain tumor formation*** (Bian et al., *Nat Meth* 2018)](https://www.nature.com/articles/s41592-018-0070-7),
created organoid models of two brain tumor types (primitive neuroectodermal
tumors and glioblastoma) using CRISPR to generate mutations in known oncogenes. 
The two conditions were generated by MYC oncogene overexpression, *MYC^OE^* (CNS-NET), and knockouts of several genes including *PTEN* and *P53* (GBM).

Differences in gene expression between two tumor models were compared with controls
and were found to differ in the sets of genes that were mis-regulated. 
The researchers first showed that the two organoid tumor models seem to show quite different
gene expression patterns using **PCA** (principal components analysis) of the top 500
genes with the highest variability compared with controls (see [**Figure 3a,b**](https://www.nature.com/articles/s41592-018-0070-7/figures/3)). 
We will go over PCA later in the course.

Next, they performed **hypergeometric tests** to ask whether all of the genes that 
were significantly **up- or down-regulated** in the two models (in comparison with 
controls) showed less overlap that expected by random chance (see [**Supplementary Figure 3**](https://www.nature.com/articles/s41592-018-0070-7/figures/9)).

If so, this would support the idea that divergent gene programs are misregulated 
in the two models.

Based on the PCA analysis (**Figure 3a**), differentially expressed genes could be separated into two different groups corresponding to the two organoid tumor models: Cluster 2 (*MYC^OE^*) and Cluster 3 (GBM).

![](HW7_data/Bian_Fig3a.png){width=50%}

**Fig. S3** shows Venn diagrams of the gene set overlaps between Clusters 2 and 3:

![](HW7_data/Bian_FigS3a.png){width=50%}

Your question is whether the differentially expressed genes in these two clusters overlap by **less** than expected by chance. Here we will focus on just the **up-regulated genes**. How will you set up the problem?


### a) Expected gene set overlap based on independence

In total, 4034 genes were up-regulated in at least one of the organoid tumor models (vs. controls). The rest of the numbers you will need are shown in the Venn diagrams in Fig. S3. A framework for organizing the data has been set up below to help get you started.

```{r, collapse=T}
## Up-regulated genes ======================================================== #
## 4034 genes up-regulated in either experiment (vs control)

ol.obs =  92 # overlap
A =  2247           # total size of Cluster 2 (Set A = bigger set)
B =  295        # total size of Cluster 3 (Set B = smaller set)
N = 4034         # total genes up-regulated in both experiments
# 
# # What is the expected overlap based on the null hypothesis of independence?
ol.exp = A * B / N

ol.exp
```


### b) Hypergeometric test

Find a p-value for the observed overlap with a hypergeometric test using `dhyper` and `pyhper`. Remember, you are looking for less overlap than expected between the two sets (is this the lower tail or the upper tail?).

First, look up the documentation on these functions.
```{r}
? phyper
? dhyper

```

Here are some additional tips to help you figure out how to parameterize the functions:

+ $x$: this is the observed overlap
+ $m$: pick one gene set, call this Set A
+ $n$: this is the total number of genes NOT in Set A (out of all the up-regulated genes)
+ $k$: the other set (Set B)
  +  Note that the maximum possible size of the overlap would be the total size of the smaller gene set (which cluster is that here?)
  + It does not really matter which set you choose to use for $m$ or $k$; the p-value will be the same either way.

```{r, collapse=T}
## p-value using hypergeometric test ========================================= #

# using CDF function

phyper(ol.obs, B, N - B, A, lower.tail= TRUE)
# using PDF function
sum(dhyper( 0:ol.obs, B, N - B, A ))

```


### c) Fisher's Exact Test

The hypergeometric test is equivalent to a one-tailed Fisher's test (but it is 
actually more efficient in R). Use a Fisher's test to make the same comparison as above. Here are some helpful hints:

+ You want to perform a one-sided test for more extreme values than the ones observed, given all possible combinations of values "conditioned on fixed margins" (which tail are you looking for here?).
+ Make a contingency table: orientation is arbitrary, but by convention put the categories "of interest" first.
  + Put the overlap in the top left cell (*a*, a.k.a. $x_{11}$).
  + Put the remainder of the A and B sets (minus the overlap) in the right (*b*, $x_{12}$) and bottom left (*c*, $x_{21}$) cells.
  + Put the remainder of the up-regulated genes in (*d*, $x_{22}$).

```{r, collapse=T}
## with Fisher's exact test ================================================== #

A.not.B = A-ol.obs
B.not.A = B-ol.obs
N.not.AB = N - B - A + ol.obs  # same as: N - B - A.not.B
contingency.table = rbind(c(ol.obs, A.not.B),
                          c(B.not.A, N.not.AB))
rownames(contingency.table) = c("overlap","Set A")
colnames(contingency.table) = c("B","Rest")
contingency.table
fisher.test(contingency.table, alternative="less")
fisher.test(contingency.table, alternative="less")$p.value

```

### d) How do the p-values compare?

```{r}

#p-value are the same for both fisher test and hypergeometric test
```


## 2) Line plots: Mean, SD, SEM

Please read the short article *Error bars (Nat Meth 2013)* provided with this assignment.

### a) What is the difference between the standard error (SEM) of the mean and standard deviation?  
```{r eval=FALSE}
# your answer here

#Standard deviation measures the dispersion of a data relative to its mean
#Standard error of the mean measured how much discrepancy there is likely to be in a sample's mean compared to the population mean. The SEM takes the SD and divides it by the square root of the sample size.

```

### b) What are some common misconceptions about interpreting error bars?
```{r eval=FALSE}

#S.D bars reflects the variation of data and not error in measurement
#Data pairs and their error bars can visually seem identical ( equal length), and ironically each represents a different p-value
#By fixing the P value to P = 0.05 and show the length of each type of bar, they had different lengths, we will likely interpret each one quite differently 
#Error bars for small sample sizesâ€”they are not robust
#When error bars over lap that doesn't mean that they are significant
#Expectation that a CI captures the mean of a second sample drawn from the same population with a CI% chance. Because CI position and size vary with each sample, this chance is actually lower

```

## 3) Cancer metabolism

In the paper [***Metabolic competition in the tumor microenvironment is a driver of cancer progression*** (Chang et al., *Cell* 2015)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4864363/), the authors use mouse models to demonstrate that in cancers, T cells are metabolically restricted by tumor glucose consumption, ultimately allowing tumor progression. The authors use line graphs in **Figure 4B**:

![](HW7_data/Chang_Fig4B.png){width=60%}

### a) What question were the researchers trying to answer in this Figure?
```{r eval=FALSE}
# By varying treatments how this will affect the tumor size overtime ?
```

### b) How many replicates were performed, and what do the error bars represent?
```{r eval=FALSE}
# they did three or more replicates, the error bars represent standard error of the mean
```

### c) Do you think this an appropriate way to represent the data? Why or why not, and how would you try to represent them?
```{r eval=FALSE}
# No because
#error bars based on the SEM reflect the uncertainty in the mean and its dependency on the sample size, because SEM bars shrink as we perform more measurements,
#here we have very small sample size, so I dont recommend using error bars using SEM specially error bars with  small sample sizes are not robust
#when dealing with paired data like  before and after treatment other types of error bars are needed 
# I would like to represent the data as individual data points
#
```
    

## 4) Spindle dynamics in evolution

The paper [***Stoichiometric interactions explain spindle dynamics and scaling across 100 million years of nematode evolution*** (Farhadifar et al., *eLife* 2020)](https://elifesciences.org/articles/55877) explores spindle dynamics in *C. elegans* using a combination of imaging methods and QTL mapping of intercross lines. Below is reproduced Figure 3 from this article:

![](HW7_data/Farhadifar_Fig3.jpg){width=80%}

### a) What question were the researchers trying to answer in this figure?
```{r eval=FALSE}
#How quantitative variations in spindle length is affected by knocking down gpr-1 and par-2 genes that are mapped to QTL1 and QTL-2 regions ?
```

### b) Panels C and D

About how many data points are there for each line? What do the error bars represent? Would you change anything about the way the data are represented?
```{r eval=FALSE}
# many data points that are estimated from 500 permutations performed independently for the two subgroups
#Error bars represent standard error
#yes, if we use boxplot in violin plots to get the sense of the spread around the median i the boxplot and also overall easier visual comparison between the 2 sets when we have the 2 violin plots
```

### c) Panels E and F

What is being plotted? What do the shaded areas represent, and why do you think the researchers chose to display the variation in their measurements in this way? Would you have done anything differently?
```{r eval=FALSE}
#the change in spindle length with respect to time when knocking down of gpr-1 and par-2 genes that are mapped to QTL1 and QTL-2 regions. 
#shaded areas represent ribbon bars using SD
#Because they wanted to show us the sense of spread around the mean when using the SD error bars.
#No I like it! it is an informative way to represent data
```


## 5) Line plots with SD or SEM

How would you plot similar graphs in R showing SD or SEM? The dataset "HW7_data.csv" contains eight replicate measurements across 20 timepoints (0-190 seconds) for a control and a treatment condition. The data are the raw (non-normalized) values used to generate the plots in Figure 6A from 
[Cipriani et al., eLife 2021](https://elifesciences.org/articles/60833).

### a) Calculate the mean, SD, SEM

Load the dataset and use the `dplyr` package to reformat it as follows:

+ Group the data by treatment and time (hint: use `group_by()`).
+ Add 3 new columns to the data frame containing group summaries for the mean, SEM, and SD (hint: use `summarise()`).
+ Add 4 new columns containing the upper and lower limits for the SEM and the SD.
  
```{r}
library(dplyr)

data <- read.csv("HW7_data.csv", header = T)
#View(data)



data_new <- data %>% 
  group_by(TREATMENT, time) %>%
  summarise(Mean = mean(Values), s.d = sd(Values), sem = sd(Values)/sqrt(length(Values)), 
            upper.limit.sem = Mean + sem, lower.limit.sem = Mean - sem,upper.limit.sd = Mean + s.d,lower.limit.sd = Mean - s.d  )
  
data_new 
  

```
    

### b) Line plot with discrete error bars showing SD

Use `ggplot2` to create a line graph to plot the mean, with discrete error bars representing the standard deviation.

+ Map the data to time (x-axis) and mean (y-axis), and use color to indicate the treatment.
+ Use a line for the geom layer.
+ Add the error bars using `geom_errorbar()` (look this up to see how to add the upper and lower boundaries). Don't forget to map the color to the treatment.
+ Add axis labels for the time (in seconds) and the values (as "Relative fluorescence").

```{r}


###SD error bars

library(ggplot2)
plot_sd <- ggplot(data = data_new, 
       mapping = aes(x = time, y = Mean))+
  geom_line(aes(col= TREATMENT)) +
  geom_errorbar(aes(ymin = lower.limit.sd, ymax = upper.limit.sd, col = TREATMENT), width = 1.5)
P_SD = plot_sd + ggtitle("SD with error bars") + xlab("time") + ylab("fluorescence")


P_SD






```


### c) Line plot with shaded regions showing SEM

Use `ggplot2` to create a line graph to plot the mean, with a shaded area representing the standard error of the mean. This plot will use almost the exact same code as the last graph, except you will use `geom_ribbon()` to display the upper and lower bounds of the SEM.
      
```{r}


library(ggplot2)
plot_sem <- ggplot(data = data_new, 
       mapping = aes(x = time, y = Mean))+
  geom_line(aes(col= TREATMENT))
  
P_SEM = plot_sem + ggtitle("SEM with error bars") + xlab("time") + ylab("fluorescence")

P_SEM + geom_ribbon(aes(x = time, ymin = lower.limit.sem, ymax = upper.limit.sem,fill= TREATMENT), 
                alpha=0.1,       
                linetype=1,      
                colour="grey70", 
                size=1)

```


### d) Which representation do you think is most effective for these data? What would you choose to do?
```{r}
#The first plot is more informative since it gives us understanding that the 2 groups ( treatment vs control) at the beginning have overlap but with time they start to be spread from each other showing no overlap between error bars. Also on the first plot we have SD error bars  and in the second plot we have SEM bars. Thats why in the first plot we can infer more information since SD is the spread around the mean
```

