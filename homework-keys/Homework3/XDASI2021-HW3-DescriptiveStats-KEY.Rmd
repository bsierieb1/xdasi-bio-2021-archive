---
title: "HW3: Describing Data and Estimating with Uncertainty"
subtitle: "XDASI Fall 2021"
author: "Elizabeth Blackburn [YOUR NAME HERE]"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    highlight: pygments
---

***Note:*** 

+ The first code chunk sets up options for knitting. When you are ready to check
if your code will knit without errors, you can remove `error=TRUE`.
+ You should always make sure to load the appropriate packages in this chunk that 
you will need later in the document. Here we have done this for you, but in 
future you will need to think about this yourself.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error = TRUE)
# remove "error = TRUE" to make knitr halt on errors
# (do this when you are ready to check if your code will knit without errors)
library(dplyr)
library(ggplot2)
library(ggpubr)
```

## Before you begin

**Download the datasets** provided for this homework and put them inside your current
working directory.

RStudio automatically sets the base directory to the current **R Project** directory.
It's probably easier for you to organize your work if you start a new R project
for this homework. Then, anytime you want to work on this or revisit it, you only
need to open this project.

Let's check to see we are in the right place and your data files are present:

```{r}
getwd()
list.files() # this directory

# if you put your data file in a sub-directory, also list all the files in that directory
# (I like to collect all my data files in a subdir called "data/")
list.files("data/")
```

***Note:*** **There is usually more than one way to do things. Below we will suggest 
at least one way to complete different tasks, but you should feel free to use any 
syntax that you prefer. Just comment out any lines that you decide not to use.**

<!-- ======================================================================= -->
# High-fat Diet Study

A **study[^1]** raises groups of mice on two different diets:

- Regular chow (11% fat)
- High-fat chow (58% fat)

They then measure differences in weight gain, glucose intolerance, and insulin resistance. 
Our scientific question is:
**Are the HF mice a good model for Type II diabetes?**

In a future exercise, we will see how statistical inference can help us discern if there is 
any meaningful difference between them. Here, we will just use this dataset to illustrate 
sampling, descriptive statistics, and the Central Limit Theorem. 


## I. Preprocessing and ata exploration

### I.1. Load the dataset

Load the data in `mice_pheno.csv` and take a look at it.

```{r}
# load the dataset
mice.pheno = read.csv("data/mice_pheno.csv", stringsAsFactors = TRUE)

# take a look at its structure and contents
str(mice.pheno)
head(mice.pheno)
summary(mice.pheno)
```

### I.2. Clean the data

It's always a good idea to check the integrity of your data files before you start working on them. 

+ Do the data look the way you expect them to? 
+ Does it have all the expected rows and columns? 
+ Are there any "funny" values? 
  + If you don't explicitly specify the type of data to be imported, R will use its best guess. This can sometimes produce surprising results!
  + For example, if your file has passed through Excel, sometimes certain strings may have gotten converted to dates automatically. This happens with some *C. elegans* gene names (and probably others), and is very annoying! Auto-conversion can be avoided by explicitly exporting some data as text.
  + Another thing that can happen is that a column could be misinterpreted as a logical, as we saw in the last homework (where only females were included, encoded simply as "F").

#### Missing data

**One common problem is that some values will be missing from the data**, which can cause a lot of problems later. Missing values are designated by `NA` and are treated as a null value by R (instead of 0).

The full mouse dataset contains some rows with missing data. How can we tell?

+ Otion 1: Use `which` and `is.na()` to find out which rows are missing bodyweight measurements.
+ Option 2: Use `subset()` and `is.na()` to do the same thing.

```{r}
# Option 1
mice.pheno[which(is.na(mice.pheno$Bodyweight)),]

# Option 2
mice.pheno %>% subset(is.na(Bodyweight))
```

We can remove rows with missing data using `complete.cases()` (there are a couple of other ways to do this also). Choose your preferred method and clean the data frame by throwing away those `NA` rows.

```{r}
# Option 1
mice.pheno = mice.pheno[complete.cases(mice.pheno),]

# Option 2
mice.pheno = mice.pheno %>% subset(complete.cases(mice.pheno))
```

#### Recode factor names

While we're at it, let's change the factors to something less cryptic.

+ Rename the Diet factors as "Chow" and "High-fat".
+ Rename the Sex factors as "Female" and "Male".

```{r}
## Fix up "diet" labels
levels(mice.pheno$Diet) = c("Chow","High-fat") 
levels(mice.pheno$Sex) = c("Female","Male") 
```


### I.3. Visualize the data

First, let's visualize the data. We have two factors: Diet and Sex, so we want to visualize both of these at the same time.

+ Draw a violin plot of Bodyweight that separates the data by Diet.
+ Superimpose narrow boxplots in white on top of the violins.
+ Also, use `facetwrap( ~ Sex)` to draw side-by side plots for females and males.
+ Since the labels seem really small by default, fix up the text annotations to make the graph more legible.

For help on tweaking the appearance of the graphs, you may want to consult one of these references:

+ [Cookbook for R: Graphs](http://www.cookbook-r.com/Graphs/){: target="blank}
+ [R Graphics Cookbook](https://r-graphics.org/){: target="blank"}
+ [Data Visualization with ggplot: Labels](https://viz-ggplot2.rsquaredacademy.com/ggplot2-labels.html){: target="blank"}

```{r fig.height=4, fig.width=6, warning=FALSE}

## Violin plot by sex and diet
ggplot(mice.pheno, aes(x=Diet, y=Bodyweight, fill=Diet)) +
  geom_violin(color="black", width=0.5) +
  geom_boxplot(fill="white", color="black", width=0.1) +
  facet_wrap(~ Sex) +
  theme( text = element_text( size = 24 ),
         axis.title = element_text( face = "bold" ))
```


### 3. Filter data

Well it looks like the mice fed the high-fat diet are heavier, but how much? Male and female mice seem to have different weights on average, so we will want to answer this question for each of them separately.

+ Find the difference in the mean weight for males and females on the HF vs. control diet, and convert this to percentage weight gain.

```{r}
# means by sex and diet
female_chow_mean = mean(mice.pheno[which(mice.pheno$Sex == "Female" &
                                      mice.pheno$Diet == "Chow"),"Bodyweight"])
female_hf_mean   = mean(mice.pheno[which(mice.pheno$Sex == "Female" &
                                      mice.pheno$Diet == "High-fat"),"Bodyweight"])
male_chow_mean = mean(mice.pheno[which(mice.pheno$Sex == "Male" &
                                         mice.pheno$Diet == "Chow"),"Bodyweight"])
male_hf_mean   = mean(mice.pheno[which(mice.pheno$Sex == "Male" &
                                         mice.pheno$Diet == "High-fat"),"Bodyweight"]  )

# differences
female_diff = female_hf_mean - female_chow_mean
male_diff   = male_hf_mean - male_chow_mean
female_diff
male_diff

# percent differences
(female_diff/female_chow_mean)*100
(male_diff/male_chow_mean)*100
```


```{r}
# make two data.frames containing just the "chow" or just the "hf" mice.
chow = mmw %>% filter(Diet == "chow")
hf = mmw %>% filter(Diet == "hf")


## make a df of just the male mice -- remove Sex column
# "mmw" => male mouse weights

# Option 1
mmw = mice.pheno[mice.pheno$Sex == "M",c("Diet","Bodyweight")]

# Option 2
mmw = mice.pheno %>% filter(Sex == "M") %>% select(Diet, Bodyweight)

# check the data frame
str(mmw)
head(mmw)
```


## Random sampling

Let's see what happens when we take random samples from these populations. Let's just consider males for now.

+ Sample 12 male individuals from the "chow" group and the same number from the "hf" group.
+ Then, take the difference in the means between the two groups.

```{r}
# subset the data

# sample 12 males from each diet
s.ctl = chow %>% sample_n(12)
s.trt = hf %>% sample_n(12)

# how different are the mean weights in the two samples?
obs.diff = mean(s.trt$Bodyweight) - mean(s.ctl$Bodyweight)
obs.diff
```

Try re-running this code a bunch of times. How do the differences between samples vary? How close are these to the mean difference between the two populations of mice?

Ultimately, we want to know if the observed differences are meaningful. Would we expect to see a difference as big as this between two random samples of control mice, just by chance? 

In a future homework we will answer this question using two different statisical methods. Today we will just get a feel for the sampling distribution of the sample mean, the SEM, and the 95% CI.


### Sampling distribution of a random variable

For this example, we have a large sample of 200+ control mice that we can use as a proxy for the two populations, but most of the time we won't have access to the full population. 

Since we have access to the entire population, we can simulate many possible outcomes of sampling from the control population. First, let's take a handful of random samples from this population, compute the means, and see what happens.

+ Use the `replicate()`, `mean()`, and `sample()` functions together to take 6 samples of 12 mice from the control population and look at the means (do not assign the output to any variable here, just take a look at the sample means). 

```{r}
# take 6 samples of 12 mice from the control population and look at the means
replicate(6, mean(sample(chow$Bodyweight, 12)) )
```

Naturally, each time we take a different sample, we get a different mean. Note that since we are taking random samples, the mean is also a **random variable**!

What happens if we take a bunch of samples from the control population, compute the mean of each sample $\bar{X}$, and look at the **distribution of the sample means**? 

```{r warning=FALSE, fig.width=6, fig.height=4}
sample.size = 12
n.samples = 100
resample = data.frame(sample.mean = replicate(n.samples, 
                                              mean(sample(chow$Bodyweight, sample.size))) )
str(resample)
head(resample)

# histogram of sample means from the `resample` data frame. Pick whatever color scheme you like.
ggplot(resample, aes(x=sample.mean)) + 
  geom_histogram(fill="lightblue", color="black", binwidth = 1) + # pick a color scheme
  
  # map `sample.mean` to the vertical line (copy syntax from previous histograms above)
  geom_vline(aes(xintercept=mean(sample.mean)),
             linetype="dashed") + xlim(c(19,45))

```

We can see that this distribution looks kind of like a bell curve -- in fact, it approximates a normal distribution. And we can empirically derive the mean and standard deviation for the distribution:

```{r}
# look at the results:
pop.mean = round(mean(chow$Bodyweight),2)
sample.dist.mean = round(mean(resample$sample.mean),2)
print(paste("Chow pop mean = ", pop.mean))
print(paste("Chow sample distribution mean = ",sample.dist.mean))
print(paste("Difference = ", round(sample.dist.mean - pop.mean, 2)))

print(paste("SD of control sample distribution: ", round(sd(resample$sample.mean),2), sep=""))
```

But wait! We've already learned that we don't need 100 or 1,000 samples in order to estimate the variation of a population from a single sample. Why is this? Because we also know two key pieces of information:

1. The mean of any sampling distribution approximates a normal distribution.
2. The variation in this distribution is a function of the sample size. 

The *standard deviation of the sampling distribution of the sample mean* (what a mouthful!!!) is the SD of the distribution in the `resample` dataframe. This is the **empirical** value of the **standard error of the mean (SEM)**. 

Howevr, the SEM is usually computed directly from a single random sample, using just two values -- the SD of the sample, and the sample size. Recall that the SEM computed using data from a single random sample is:

$$ SEM = \frac{s}{\sqrt{n}}$$

Below we will write a function that takes a random sample from a population and returns the SEM for it.

+ The function takes two parameters:
  + sample.df = A data frame with the population data we want to sample from
  + sample.size = A sample size, set to 12 by default (so, if you don't specify a size, it will use 12)
  
When we call the function, we pass the name of a dataframe to it, which is placed into a temporary container called `sample.df` inside the function. This allows us to call the same function for different populations.

```{r}
# ============================================================================ #
# A function to compute the SEM based on a single sample from a population
sem = function(sample.df, sample.size=12){
  
  # take a new sample of 12 mouse bodyweights from the chow population
  # random.sample should be a **vector of bodyweights**
  random.sample = sample(sample.df$Bodyweight, sample.size, replace = FALSE)
  
  # formula for the SEM of a random sample
  return( round(sd(random.sample)/sqrt(sample.size), 2) )
}
# ============================================================================ #

# take the SD of all the sample means in the `resample` distribution
# this is the **empirical SD** of the sampling distribution of the sample means!
print(paste("SD of distribution of 'chow' sample means: ", 
            round(sd(resample$sample.mean),2), sep=""))

# repeat sampling from the chow population 10 times (with default sample size = 12)
print("SEM of individual samples:")
replicate(10,sem(chow))
```

As you can see, the SEM also has a sampling distribution just like the sampling distribution of the sample mean, since it is derived from random samples. Sometimes it is pretty close to the SD of the sampling distribution, and sometimes it is pretty far away.


## Confidence intervals

To quantify our uncertainty in our sample estimate for the population mean, we will compute a 95% confidence interval for a bunch of random samples. Remember from class that we can estimate the 95% confidence interval for a sample as:

$$ CI_{95} = \bar{X}-1.96*SEM \le \mu \le \bar{X}+1.96*SEM$$

First, let's calculate the bounds of the 95% CI for a single sample of 12 mice from the chow population.

```{r}
# the sample
sample.size = 12

# create a sample of bodyweights from the chow population (this should be a numerical vector)
ctl = sample(chow$Bodyweight, sample.size, replace = FALSE)

# compute SEM
sem = sd(ctl)/sqrt(length(ctl))

# compute bounds
print("95% CI for an individual sample:")
c(mean(ctl) - 1.96*sem, mean(ctl) + 1.96*sem)
```

What if we repeat this for 100 random samples? To compute each SEM, we will use the actual population SD, $\sigma$, since in this example we already know it, and use it to compute a 95% CI for each sample.

The, we will draw a plot showing whether each confidence interval ***does or does not*** contain the true sample mean for the control ("chow") population. On the plot, we will show the population mean $\mu$ for both the chow and the high-fat diet mice. 

```{r fig.width=5, fig.height=7, collapse=TRUE}
n.samples = 100   # number of random samples
N = 12   # sample size
Q = 1.96 # sigma for +/- 47.5% of a normal distribution

# set up a plot showing a vertical line with the true mean for each population
chowPop = chow$Bodyweight
hfPop = hf$Bodyweight
plot(mean(chowPop)+c(-7,7),c(1,1),type="n",
     xlab="weight",ylab="interval",ylim=c(1,n.samples))
abline(v=mean(chowPop))
abline(v=mean(hfPop), lty="dashed")

# display the 95% CI for a bunch of random samples
for (i in 1:n.samples) {
  chow.sample = sample(chowPop,N) # take a random sample
  se = sd(chow.sample)/sqrt(N)           # compute SEM
  interval = c(mean(chow.sample)-Q*se, mean(chow.sample)+Q*se) # compute 95% CI
  
  # draw the 95% CI -- color it green if it contains the true population mean, or red if not
  covered = mean(chowPop) <= interval[2] & mean(chowPop) >= interval[1]
  color = ifelse(covered,"forestgreen","red")
  lines(interval, c(i,i), col=color)
}
```

Re-run the above code block a bunch of times. Around what proportion of these confidence intervals do NOT contain the true population mean? Where does your high-fat diet sample fall within these?

## Hypothesis testing

Next time we will quantify the probability that a sample of high-fat mice comes from a different distribution than the "chow" distribution we have constructed here -- that is, can we reject the null hypothesis that the high-fat diet has no significant effect on our mice? 

First we will derive a $p$-value for this empirically by comparing sample distributions taken from both populations, and then we will use a standard statistical test, the $t$-test, to compute a $p$-value from multiple individual samples.

<!-- footnote -->

[^1]: The high-fat diet-fed mouse: a model for studying mechanisms and treatment of impaired glucose tolerance and Type II diabetes.
MS Winzell and B Ahren, _Diabetes_ 2004; 53:S215-219
