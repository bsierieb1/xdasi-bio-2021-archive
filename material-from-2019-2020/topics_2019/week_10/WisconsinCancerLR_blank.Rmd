---
title: "WisconsinBreastCancer"
author: "Manpreet S. Katari"
output: html_document
---

# Wisconsin Breast Cancer Dataset

The following data was obtained from a study where 3D images were taken of a breast mass. The features are measurements of the mass. We will try to create a logistic regression model to predict the diagnosis (m=malignant and b=benign). For a more detail understanding of the values see the link below:

https://www.kaggle.com/uciml/breast-cancer-wisconsin-data

## Visualize the data

The file is provided in as a csv file called *data.csv*. Read it in and call it **cancer_data**.

```{r, echo=T}
install.packages("tidyverse")

library(tidyverse)

cancer_data = read_csv("data.csv")
cancer_data
```

The four features we are interested in are *radius_mean*, *texture_mean*, *smoothness_mean*, *compactness_mean*. Create a plot for each variable to visualize the distribution of the values between *malignant* and *benign* samples. Which of the four variables will be most accurate in predicting by itself ? Explain why. (Hint - try creating boxplots)


```{r}
ggplot(cancer_data, aes(x=diagnosis, y=radius_mean)) +
  geom_violin()+
  geom_boxplot(width=.1)

ggplot(cancer_data, aes(x=diagnosis, y=texture_mean)) +
  geom_violin()#+

ggplot(cancer_data, aes(x=diagnosis, y=smoothness_mean)) +
  geom_violin()#+

ggplot(cancer_data, aes(x=diagnosis, y=compactness_mean)) +
  geom_violin()#+


```



# Predict Using logistics regression

Using the glm() function we are going to create a model for each variable. Logistic regression works on binary response so we have to do first convert the all Benign to 0 and Malignant to 1.

1) Split the dataframe into two dataframes, call it **alldata**.

```{r, echo=T, eval=T}

alldata = split(cancer_data, cancer_data$diagnosis)

dim(alldata$B)
dim(alldata$M)


```


2) Set the diagnosis in Benign dataframe to 0 and diagnosis in Malignant to 1. 

```{r,echo=T, eval=T}
alldata$B$diagnosis = 0
alldata$M$diagnosis = 1

```


3) Before we create our models, let's first remove a fraction of our data for testing purpose.

Randomly select 70 of the Benign samples and 40 of the Malignant samples and save them in another data frame called *cancer_test*.

```{r}

benign_test_index = sample(nrow(alldata$B), 70)
malignant_test_index = sample(nrow(alldata$M), 40)

benign_test = alldata$B[benign_test_index,]
malignant_test = alldata$M[malignant_test_index,]

cancer_test = rbind(benign_test, malignant_test)
```

The remaining 459 samples should now be in a difference data frame called *cancer_training*.  to both *cancer_training* and *cancer_test*: 


```{r, echo=T, eval=T}
benign_training = alldata$B[-benign_test_index,]
malignant_training = alldata$M[-malignanat_test_index,]
cancer_training = rbind(malignant_training, benign_training)
```

4) make sure the new diagnosis variable is a factor.


```{r, echo=T, eval=T}
dim(cancer_test)
dim(cancer_training)

is.factor(cancer_training$diagnosis)

cancer_training$diagnosis = as.factor(cancer_training$diagnosis)
cancer_test$diagnosis = as.factor(cancer_test$diagnosis)

```

Now build the model for each variable using cancer_training and test it using cancer_test.
Calculate accuracy, recall, and true negative rate to determing which of the four variables is the most helpful predictor.

```{r, echo=T, eval=T}

radius_glm = glm(diagnosis ~ radius_mean , family="binomial",
                 data=cancer_training)

summary(radius_glm)

radius_prediction = predict(radius_glm, newdata = cancer_test, type="response")

radius_prediction

#radius_prediction_binary = round(radius_prediction)


# when > 0.5 is predicting malignant
radius_prediction_binary = rep(0, times=length(radius_prediction))
radius_prediction_binary[radius_prediction > .5]=1
table(cancer_test$diagnosis, radius_prediction_binary)

# when > .25 is predicting malignant
radius_prediction_binary = rep(0, times=length(radius_prediction))
radius_prediction_binary[radius_prediction > .25]=1
table(cancer_test$diagnosis, radius_prediction_binary)

#length(cancer_test$diagnosis)
#length(radius_prediction_binary)
#radius_prediction
```

In order to assess the performance of our model, we will calculate the AUC ( Area under the curve. ) The Curve is created by plotting **sensivity** vs **1-specificity**. Generally a line is plotted from 0,0 to 1,1. A straight line with a slope of 1 represents events that would happen just by chance, which would have an AUC of 0.5. We are interested in curves that are much larger than this line.  

To do this we will use a package called **AUC**. If you haven't already installed it, please use the following command.
```{r eval=F}
install.packages("AUC")
```

Once it has been installed, then you simply load it using the **library** command.

```{r}
library(AUC)

roc_result = roc(radius_prediction,factor(cancer_test$diagnosis) )
plot(roc_result)
auc(roc_result)



```

```{r}
lapply(roc_result, head)


```

Now let's test the radius model. First we will perform our predictions using the **predict** function ( just like in regression ) and provide the **cancer_test** dataset.

```{r, echo=T, eval=T}
############# Texture

# create logistic regression using only texture as the variable
#  - use only the training dataset.
#
# calculate the predictions
# create the auc plot


```

Now we use the **roc** command with the **Predicted** values and also the **True** values. Once the ROC object is returned, we can get lots of different types of statistics, including **auc** by using the **auc** function. Other functions that can be used on the object include : specificity, sensitivity, accuracy, roc, auc, and also plot.

```{r}


```

We can repeat the steps for the other variables to see how they perform.


```{r, echo=T, eval=T}
############# Texture

# create logistic regression using only texture as the variable
#  - use only the training dataset.
#
# calculate the predictions
# create the auc plot

```



```{r, echo=T, eval=T}
############# Smoothness

```


```{r, echo=T, eval=T}
############# Compactness

```

Finally, let's create a model with all the variables. Do you think the performance will be better or worse ?

```{r}


```
