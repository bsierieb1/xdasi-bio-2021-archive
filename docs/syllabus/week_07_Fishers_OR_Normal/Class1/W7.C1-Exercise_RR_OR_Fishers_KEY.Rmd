---
title: "Exercise: RR, OR, Fisher's Exact Test"
subtitle: "XDASI Fall 2021"
date: "10/12/2021"
output:
  html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
```

## Is high blood pressure a risk factor for stroke?

Consider two different experimental designs for determining whether high blood pressure is a risk factor for strokes:

+ **Design 1** 
  + 2000 men between the ages of 70-80 are chosen at random from the population.
  + These are divided into groups with and without a history of high blood pressure.
  + The number of men in each group who experienced a stroke sometime within the following 5 years is recorded.
 
+ **Design 2**
  + 2000 men between the ages of 70-80 are recruited for a study, of which 1000 have never had a stroke and 1000 have had a stroke in the last 5 years.
  + The proportion of each group who have a history of high blood pressure is recorded.

The data might look something like this:

**Design 1**
```{r, echo=F}
## Design 1 ========================= #
Stroke    = c(100,50)   # total =  200
NoStroke = c(600,1250)  # total = 1800
data_matrix1 = rbind(Stroke, NoStroke)
colnames(data_matrix1) = c("HiBP","LoBP")

# kable is a table generator from the knitr package
kable(data_matrix1)
```

**Design 2**
```{r, echo=F}
## Design 2 ========================= #
Stroke   = c(200,800)  # total =  1000
NoStroke = c(50,950)   # total = 1000
data_matrix2 = rbind(Stroke, NoStroke)
colnames(data_matrix2) = c("HiBP","LoBP")
kable(data_matrix2)
```

## 1) Compute RR and OR manually

Let's compute both $RR = \frac{p_{Stroke|HiBP}}{p_{Stroke|LoBP}}$ and 
$OR = \frac{p_{stroke|HiBP}/(1-p_{Stroke|HiBP})}{p_{Stroke|LoBP}/(1-p_{Stroke|LoBP}}$ for both scenarios:

```{r}
## Design 1 ================= #
a=data_matrix1[1,1]
b=data_matrix1[1,2]
c=data_matrix1[2,1]
d=data_matrix1[2,2]

p1 = a/(a+c)
p2 = b/(b+d)
o1 = a/c
o2 = b/d
RR = p1 / p2
#OR = (p1/(1-p1)) /(p2/(1-p2))
OR = (a/c) / (b/d) # equivalent

# p1
# p2
# o1
# o2

cat("Design 1:\n", "RR =",RR,"\n", "OR =",OR,"\n")

## Design 2 ================= #
a=data_matrix2[1,1]
b=data_matrix2[1,2]
c=data_matrix2[2,1]
d=data_matrix2[2,2]

p1 = a/(a+c)
p2 = b/(b+d)
o1 = a/c
o2 = b/d

RR = p1 / p2
#OR = (p1/(1-p1)) /(p2/(1-p2))
OR = (a/c) / (b/d) # equivalent

# p1
# p2
# o1
# o2

cat("Design 2:\n", "RR =",RR,"\n", "OR =",OR,"\n")
```

## 2) Use R commands to compute RR and OR

We can use the `riskratio()` and `oddsratio()` functions from the "epitools" package to compute the risk ratio automatically.

***Note 1:*** Look at the documentation for this command. It expects a table in a different format than what we have here! We can specify to change this by setting the `rev` parameter. We also need to transpose the table first.

```{r}
library(epitools)

data_matrix1
t(data_matrix1)

riskratio(t(data_matrix1),correction = F, rev="both")
oddsratio(t(data_matrix1),correction = F, rev="both")

riskratio(t(data_matrix2),correction = F, rev="both")
oddsratio(t(data_matrix2),correction = F, rev="both")
```

The above method seems most straightforward to me logically ... but you can also reverse the matrix beforehand, and then execute the commands without adding `rev="both"`:

```{r eval=FALSE}
riskratio(rev(data_matrix1), correction=F)
oddsratio(rev(data_matrix1), correction=F)

riskratio(rev(data_matrix2), correction=F)
oddsratio(rev(data_matrix2), correction=F)
```


***Note 2: Beware!!!*** There is something funny about the results when you reverse the matrix first and then feed it as a vector to `riskratio()`, vs. reverse it and feed it as a matrix, or just transpose it. This can be really confusing!!!

```{r eval=FALSE}
library(epitools)

# compare different input formats============================================ #
data_matrix1
rev(data_matrix1)          # reverses order as d-b-c-a

matrix(rev(data_matrix1),  # flips flips a-d, b-c
       nrow=2, ncol=2)
matrix(rev(data_matrix1),  # flips a-d
       nrow=2, ncol=2,
       byrow = TRUE)
t(data_matrix1)            # flips b-c

# risk ratio ================================================================ #
#riskratio(data_matrix1, correction=F, rev="both")     # this is not correct
#riskratio(t(data_matrix1), correction=F)              # this is also incorrect

riskratio(t(data_matrix1), correction=F, rev="both")    # this works!

#riskratio(matrix(rev(data_matrix1), nrow=2, ncol=2),  # this also does not work! ... even with rev="both"
#          correction=F)                               # (default is byrow = FALSE)
#                                                      # then you need to traspose again, too complicated!

riskratio(rev(data_matrix1), correction=F)              # this works!

# riskratio(matrix(rev(data_matrix1),                   # this works too ... need to make matrix by row
#                  nrow=2, ncol=2,
#                  byrow = TRUE),
#           correction=F)

# riskratio(t(matrix(rev(data_matrix1),                  # this works, but too complicated!
#                    nrow=2, ncol=2,                     # you need to transpose the matrix also
#                    byrow = FALSE)),                    # (default is byrow = FALSE)
#          correction=F)

# odds ratio ================================================================ #
oddsratio(t(data_matrix1), correction=F, rev="both")
oddsratio(t(data_matrix2), correction=F, rev="both")
```


## 3) How do the RR and OR compare for these two scenarios?

***We can see that for Design 1, the RR and OR are similar.***

***However, in the second case, RR is very different from OR.***

+ It really doesn't make sense to try to compute RR for Design 2, because we have vastly exaggerated the proportion of people who have had a stroke by picking 1000 people in each focal group. So ***"the probability that someone with HiBP has had a stroke"*** is not reflective of the actual incidence of strokes among a random sample of men with HiBP, and likewise for ***"the probability that someone with LoBP has had a stroke"***.

***In contrast, the OR is about the same in the two studies.***

+ This makes sense, because even though the total number of people with a Stroke is way higher in Design 2, we still expect that the ***relative ratios*** of people who did vs. didn't have a stroke in the two groups to be about the same as for Design 1.


## 4) Use Fisher's Exact Test 

Now use Fisher's test to get a $p$-value and OR estimate for these data. **Try out both a 2-sided and a 1-sided test for both datasets** (`alternative="greater"`).

```{r}
fisher.test(data_matrix1)
fisher.test(data_matrix2)

fisher.test(data_matrix1, alternative="greater")
fisher.test(data_matrix2, alternative="greater")
```

```{r collapse=TRUE}
fisher.test(data_matrix1)$p.value
fisher.test(data_matrix2)$p.value

fisher.test(data_matrix1, alternative="greater")$p.value
fisher.test(data_matrix2, alternative="greater")$p.value
```

***These are very similar to the results we got previously.*** The odds ratios differ slightly, though, possibly due to minor differences in rounding.

+ Note that the reported Fisher's $p$-value from the `epitools` package is the same as a **2-sided** `fisher.test()`. 
+ If you want to do a one-sided test, you should use Fisher's and specify that explicitly (per above).
+ Also note that the overall report from Fisher's just says `p-value < 2.2e-16`, but ***you can get the precise value using the `$p.value` notation***.


## 5) Use `phyper()` function

Now use the hypergeometric distribution to get a $p$-value for these data. How do the results compare with your results above?

```{r}
data_matrix1
data_matrix2
# phyper(q, m, n, k, lower.tail = FALSE)
# phyper(a, a+b, c+d, a+c, lower.tail = FALSE)
#  q = observation (a   = stroke & high BP)
#  m = white balls (a+b = stroke, a.k.a. "success")
#  n = black balls (c+d = healthy, a.k.a. "failure")
#  k = total draws (a+c = High BP)

# Design 1
a=data_matrix1[1,1]
b=data_matrix1[1,2]
c=data_matrix1[2,1]
d=data_matrix1[2,2]
phyper(a - 1, a+b, c+d, a+c, lower.tail = FALSE)

# Design 2
a=data_matrix2[1,1]
b=data_matrix2[1,2]
c=data_matrix2[2,1]
d=data_matrix2[2,2]
phyper(a - 1, a+b, c+d, a+c, lower.tail = FALSE)

```

***These are exactly the same as the $p$-values for a one-sided Fisher's test.***


## 6) Compute the significance using $\chi^2$ tests

How do the values compare?

```{r}
chisq.test(data_matrix1)
chisq.test(data_matrix2)

chisq.test(data_matrix1)$p.value
chisq.test(data_matrix2)$p.value
```

***Again, very similar and highly significant results, but they are not exactly the same since this is an approximate test. Also note that the result is equivalent to a two-sided test, since you cannot perform a one-sided test with this method.***
