---
title: "Introduction to probability and distributions, Part 1"
subtitle: "XDASI Fall 2021"
date: "9/20/2021"
output:
  html_document:
    toc: yes
    toc_float: yes
    toc_depth: 3
    code_folding: hide
  pdf_document:
    toc: yes
    toc_depth: 3
---

<!-- Note: add `class.source="fold-show"` to top of R block to show code by default -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css, echo=FALSE}
.qbox {
  padding: 1em;
  background: cornsilk;
  border: 1px solid burlywood;
  border-radius: 5px;
}

.bluebox {
  padding: 1em;
  background: #d8ecf3;
  border: 1px solid cornflowerblue;
}

h1 {color: mediumblue}
h2 {color: mediumblue}
h3 {color: mediumblue}
h4 {color: mediumblue; font-style: italic}
```

# References

+ **Whitlock & Schluter, Chapter 5: Probability**
+ **Optional**: ***Aho, Foundational and Applied Statistics for Biologists with R***
  + [**Chapter 2**](https://drive.google.com/file/d/1cpC3ofcP9DIB8vDieE1lBVVAesWklCyM/view?usp=sharing)
  + [**Chapter 3.1-3.2**](https://drive.google.com/file/d/1ck7QGKh1TS_lo_BCjBHMk4LSB-TO2sEN/view?usp=sharing)

# Classical Probability

At its core, statistics is about probabilities and probabilistic inference. So we need to build some common vocabulary to talk about probability.

## Terminology

 Let's start with some of the basics:

<!-- ======================================================================= -->
<div class="qbox">
$\Rightarrow$ ***Question: What is a variable?***

<details closed markdown="block">
  <summary>Answer</summary>
  
+ Something whose value can change. 

For example, the formula for instantaneous velocity of a falling body is:

$$f(t) = gt$$

+ where $g=9.8m/s^2$ is acceleration due to gravity (a constant), and
+ $t = time (sec)$ (a variable)


</details>
</div>
<!-- ======================================================================= -->

## Deterministic vs. probabilistic models

<!-- ======================================================================= -->
<div class="qbox">
$\Rightarrow$ ***Q: What is a deterministic model?***

<details closed markdown="block">
  <summary>Answer</summary>
  
+ Something that when given the same inputs, will always produce the same output.
+ Such models are useful conceptually, but almost never characterize real-world phenomena.

</details>
</div>
<!-- ======================================================================= -->
<p>
<!-- ======================================================================= -->
<div class="qbox">
$\Rightarrow$ ***Q: What is a probabilistic model?***

<details closed markdown="block">
  <summary>Answer</summary>
  
+ A model that incorporates **random variables**.
+ Such models need not produce **exact** outputs, but the **most probable** outcome.

For example, a probabilistic model for the instantaneous velocity of a falling body is:

$$f(t) = gt + \varepsilon$$

+ where $\varepsilon$ represents measurement error, and
+ the expected value of $\varepsilon$ is zero: $\bar{\varepsilon} = 0$.
+ Values of $\varepsilon$ that are close to zero will occur with the highest frequency.
+ This value represents the **maximum likelihood**.

</details>
</div>
<!-- ======================================================================= -->

## Random variables and random trials

When we do experiments with an unknown outcome, we need a common framework for thinking about the process and outcomes. Let's review some basic concepts:

<!-- ======================================================================= -->
<div class="qbox">
$\Rightarrow$ ***Q: What is a random variable?***

<details closed markdown="block">
  <summary>Answer</summary>
  
+ Something whose value cannot be known preceding a measurement (a.k.a. **trial**).

</details>
</div>
<!-- ======================================================================= -->
<p>
<!-- ======================================================================= -->
<div class="qbox">
$\Rightarrow$ ***Q: What is a random trial?***

<details closed markdown="block">
  <summary>Answer</summary>
  
+ A process with two or more possible outcomes that are not predictable.

</details>
</div>
<!-- ======================================================================= -->
<p>
<!-- ======================================================================= -->
<div class="qbox">
$\Rightarrow$ ***Q: What is an event?***

<details closed markdown="block">
  <summary>Answer</summary>
  
+ An observed outcome of a random trial.

</details>
</div>
<!-- ======================================================================= -->
<p>
<!-- ======================================================================= -->
<div class="qbox">
$\Rightarrow$ ***Q: What is a probability, in terms of random trials?***

<details closed markdown="block">
  <summary>Answer</summary>
  
+ The proportion of random trials with a particular outcome.
+ The probability always between zero and one:  $0 \le P \le 1$ 

In mathematical notation, we can write:

$$P[A] = \frac{N(A)}{N}$$

Which is to say, "the ***probability*** of event $A$" equals the ***proportion*** of events with outcome $A$ relative to all possible outcomes.

</details>
</div>
<!-- ======================================================================= -->


<!-- ======================================================================= -->

# Probability Distributions

A ***probability distribution*** describes the probabilities of all possible outcomes of a random variable.

## Quantitative random variables

**Discrete** vs. **continuous** distributions describe situations in which there are a ***limited*** vs. an ***infinite*** number of outcomes.

## Some terminology

To write mathematical formulas for distributions, we need some notation to describe random variables, outcomes, and probability distributions:

- A random variable, $X$
- A (continuous) random variable outcome, $x$
- Discrete variable outcomes are called _mass points_ $x_i$
- A PDF, $f(x)$
- The output generated by a PDF, a $density$
- A cumulative distribution function (CDF), $F(x)$

## Probability density functions

A **probability density function (PDF)** is a mathematical expression that describes the distribution of all possible outcomes for a random variable.

- A ***discrete*** probability density function is more technically called a **probability mass function (PMF)**, but we will commonly refer to these as PDFs instead.

The **density function**, written as $f(x)$, gives the ***height*** of a PDF for any outcome $x$. Both types of PDFs will be valid $iff$ ("if and only if"):

1. $f(x) \ge 0, \forall x \in \mathbb{R}$
2. $\sum_x f(x) = 1$ (discrete PDF) or $\int_{-\infty}^{\infty} f(x) dx = 1$ (continuous PDF)

In other words,

+ the density function must be zero or positive for all possible outcomes, and 
+ the total probability of all possible outcomes must equal one. 

#### Thus, the total area under any probability density always equals one.

Usually, discrete distributions are illustrated using histograms, and continuous PDFs are illustrated using line graphs, for example:

```{r}
# ============================================================================ #
# binomial

## A short function to compute number of ways to get 
## a total face value for 2 fair dice, ranging from 2 to 12
ncomb.2dice = function (value) {
  # initialize an empty vector of length 12 with all zeroes
  combos_2dice = rep(0,12)
  for (i in 1:6) {  # compute all the combinations
    for (j in 1:6) {
      index = i+j
      combos_2dice[index] = combos_2dice[index] + 1
    }
  }
  return(combos_2dice[value]) # return the value(s) of interest
}
face.count = ncomb.2dice(2:12)
two_dice = data.frame(sum = 2:12, count = face.count, prop = face.count/sum(face.count))


# ============================================================================ #
# standard normal
z.scores = seq(-3,3,by=.1)
d.values = dnorm(z.scores)

# ============================================================================ #
# plots
par(mfrow=c(1,2))

plot(two_dice$sum, two_dice$prop, type="h",
     xlab="Face value", ylab="Point probability",
     main = "PMF for total face value of two fair dice")

plot(z.scores, d.values,
     type = "l",
     xlab="Z-score", ylab="Density",
     main = "PDF of the standard normal")
```


# Distribution functions

## The PDF

The PDF answers the question, for a particular probability distribution, "What is the probability of observing a value **exactly equal to** $x$ as an outcome of the random variable $X$?" It is the _relative frequency_ of a particular outcome, given all possible outcomes. 

### Discrete random variables

Since all possible values of $x$ are discrete, the ***density*** at any point, $x_i$, is ***equivalent to a probability***. Thus we can write:

$$f(x) = P(X=x),\ \ \ x \in X = \{x_1, x_2, ...\}.$$

### Continuous random variables

A really important fact to keep in mind is ***for a continuous variable, the probability at any discrete value of $x$ is zero***.

<!-- == TEMPLATE =========================================================== -->
<div class="qbox">
$\Rightarrow$ ***Q: Why is this the case?***

<details closed markdown="block">
  <summary>Answer</summary>
  
+ Because it is necessary to integrate across some interval to get a finite area under a continuous curve.

Note that continuous distributions, we will see the density may sometimes exceed one across a range of values. Nevertheless, **the total area under any PDF is always equal to one**.

</details>
</div>
<!-- ======================================================================= -->


## The CDF

The **cumulative** distribution function answers the question, "What is the probability of observing a value **less than or equal to** $x$ as an outcome?" This is called a ***lower-tailed probability***.

It can also be used to answer the question, "What is the probability of observing a value **greater than** $x$?" This is the ***upper-tailed probability*** and is obtained by subtracting the value of the CDF at $x$ from 1.

The CDF for a random variable $X$ is denoted $F(x)$ and gives the **lower-tail probability** $P(X \le x)$ for the corresponding PDF. This probability is given by the **total area** underneath a density, for all outcomes **up to and including** the value $x$.

### Discrete random variables

For a **discrete** random variable, the total probability is the ***sum*** of the probabilities for each possible value from the smallest one up to the value of interest, $x$:

$$ F(x) = P(X \le x) = \sum_{x_i \le x} f(x_i) $$

### Continuous random variables

For a **continuous** random variable, we find the total probability using ***integration***, which gives us the area under a curve: 

$$ F(x) = P(X \le x) = \int_{-\infty}^x f(t)dt$$

+ The equation for the CDF says that the total probability of getting a value at least as big as $x$ is the area under the curve from minus infinity up to $x$. 
+ Note that to be proper, we called the continuous variable of integration in the above formula $t$, since we are using it to find $x$. This is just a formality. 

Closed forms of some continuous distribution functions (such as a uniform distribution) allow solutions to be found without the need for integration. 

**Fortunately, many distribution functions are already built into R, so we don't usually have to worry about manual summation or integration!** *(R also provides the capability to perform integration directly, if you want to check that the built-in functions are giving you the correct answer.)*


# Distribution Functions in R

In R, there are four families of commands relating to distributions that you should become familiar with. For a *normal* distribution, these are:

- **rnorm**: generates ***random samples*** from the normal distribution
- **dnorm**: gives the ***density function (PDF)***
- **pnorm**: gives the ***cumulative distribution function (CDF)***
- **qnorm**: gives the inverse CDF, a.k.a. the ***quantile function***

You will learn how to use all of these.

<!-- ======================================================================= -->

## Set theory and notation

+ Set
+ Element
+ Subset
+ Sample space
+ Event
+ Empty set
+ Probability of an event
+ Proportion
+ Sample space
+ Null set

## Relationships between outcomes

+ Disjoint sets (mutual exclusion)
  + Intersect
  + Union (addition rule)
  + Example: Blood type
+ Nondisjoint sets
  + Intersect
  + Union (general addition rule)
  + Example: Blood type
+ Independence
  + Multiplication rule
  + Addition
  + Can mutually exclusive outcomes be independent?
  + How common is independence?

<!-- ======================================================================= -->


<!-- ======================================================================= -->
<!-- == TEMPLATE =========================================================== -->
<div class="qbox">
$\Rightarrow$ ***Question: ?***

<details closed markdown="block">
  <summary>Answer</summary>
  
+ Answer.

</details>
</div>
<!-- ======================================================================= -->
